{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QuickStart + Introduction.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "iaUjEjExo3Ru",
        "5tpYptkopB9v",
        "rfkqXDtOsHDY"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaUjEjExo3Ru",
        "colab_type": "text"
      },
      "source": [
        "# ParlAI Quickstart"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Cjhmff6o9ey",
        "colab_type": "text"
      },
      "source": [
        "## Install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ytu2Gyi6oeTT",
        "colab_type": "code",
        "outputId": "1ce64866-9858-41f7-f211-812517f17206",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!git clone https://github.com/facebookresearch/ParlAI.git ParlAI"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ParlAI'...\n",
            "remote: Enumerating objects: 157, done.\u001b[K\n",
            "remote: Counting objects: 100% (157/157), done.\u001b[K\n",
            "remote: Compressing objects: 100% (120/120), done.\u001b[K\n",
            "remote: Total 30516 (delta 76), reused 88 (delta 37), pack-reused 30359\u001b[K\n",
            "Receiving objects: 100% (30516/30516), 58.62 MiB | 9.46 MiB/s, done.\n",
            "Resolving deltas: 100% (21680/21680), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2qt4i2_pgkl",
        "colab_type": "code",
        "outputId": "06a69c8a-7666-454e-e1af-6c3fcfb100d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!cd ParlAI; python setup.py develop"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running develop\n",
            "running egg_info\n",
            "creating parlai.egg-info\n",
            "writing parlai.egg-info/PKG-INFO\n",
            "writing dependency_links to parlai.egg-info/dependency_links.txt\n",
            "writing entry points to parlai.egg-info/entry_points.txt\n",
            "writing requirements to parlai.egg-info/requires.txt\n",
            "writing top-level names to parlai.egg-info/top_level.txt\n",
            "writing manifest file 'parlai.egg-info/SOURCES.txt'\n",
            "reading manifest template 'MANIFEST.in'\n",
            "writing manifest file 'parlai.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "Creating /usr/local/lib/python3.6/dist-packages/parlai.egg-link (link to .)\n",
            "Adding parlai 0.1.20200516 to easy-install.pth file\n",
            "\n",
            "Installed /content/ParlAI\n",
            "Processing dependencies for parlai==0.1.20200516\n",
            "Searching for websocket-server==0.4\n",
            "Reading https://pypi.org/simple/websocket-server/\n",
            "Downloading https://files.pythonhosted.org/packages/74/64/e86581ee7775a2e08aca530b41e1a1e3ee6b320233b1eff301dcb86d1636/websocket_server-0.4.tar.gz#sha256=91cd4b565d1e1b00ef107abcb2840a8090868b19543f3b38e1962d5f975d0c04\n",
            "Best match: websocket-server 0.4\n",
            "Processing websocket_server-0.4.tar.gz\n",
            "Writing /tmp/easy_install-b08oan7d/websocket_server-0.4/setup.cfg\n",
            "Running websocket_server-0.4/setup.py -q bdist_egg --dist-dir /tmp/easy_install-b08oan7d/websocket_server-0.4/egg-dist-tmp-jd10wyge\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "Moving websocket_server-0.4-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding websocket-server 0.4 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/websocket_server-0.4-py3.6.egg\n",
            "Searching for websocket-client==0.56.0\n",
            "Reading https://pypi.org/simple/websocket-client/\n",
            "Downloading https://files.pythonhosted.org/packages/29/19/44753eab1fdb50770ac69605527e8859468f3c0fd7dc5a76dd9c4dbd7906/websocket_client-0.56.0-py2.py3-none-any.whl#sha256=1151d5fb3a62dc129164292e1227655e4bbc5dd5340a5165dfae61128ec50aa9\n",
            "Best match: websocket-client 0.56.0\n",
            "Processing websocket_client-0.56.0-py2.py3-none-any.whl\n",
            "Installing websocket_client-0.56.0-py2.py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding websocket-client 0.56.0 to easy-install.pth file\n",
            "Installing wsdump.py script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/websocket_client-0.56.0-py3.6.egg\n",
            "Searching for Unidecode==1.1.1\n",
            "Reading https://pypi.org/simple/Unidecode/\n",
            "Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl#sha256=1d7a042116536098d05d599ef2b8616759f02985c85b4fef50c78a5aaf10822a\n",
            "Best match: Unidecode 1.1.1\n",
            "Processing Unidecode-1.1.1-py2.py3-none-any.whl\n",
            "Installing Unidecode-1.1.1-py2.py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding Unidecode 1.1.1 to easy-install.pth file\n",
            "Installing unidecode script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/Unidecode-1.1.1-py3.6.egg\n",
            "Searching for typing-extensions==3.7.4.1\n",
            "Reading https://pypi.org/simple/typing-extensions/\n",
            "Downloading https://files.pythonhosted.org/packages/03/92/705fe8aca27678e01bbdd7738173b8e7df0088a2202c80352f664630d638/typing_extensions-3.7.4.1-py3-none-any.whl#sha256=cf8b63fedea4d89bab840ecbb93e75578af28f76f66c35889bd7065f5af88575\n",
            "Best match: typing-extensions 3.7.4.1\n",
            "Processing typing_extensions-3.7.4.1-py3-none-any.whl\n",
            "Installing typing_extensions-3.7.4.1-py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding typing-extensions 3.7.4.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/typing_extensions-3.7.4.1-py3.6.egg\n",
            "Searching for tqdm==4.36.1\n",
            "Reading https://pypi.org/simple/tqdm/\n",
            "Downloading https://files.pythonhosted.org/packages/e1/c1/bc1dba38b48f4ae3c4428aea669c5e27bd5a7642a74c8348451e0bd8ff86/tqdm-4.36.1-py2.py3-none-any.whl#sha256=dd3fcca8488bb1d416aa7469d2f277902f26260c45aa86b667b074cd44b3b115\n",
            "Best match: tqdm 4.36.1\n",
            "Processing tqdm-4.36.1-py2.py3-none-any.whl\n",
            "Installing tqdm-4.36.1-py2.py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding tqdm 4.36.1 to easy-install.pth file\n",
            "Installing tqdm script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/tqdm-4.36.1-py3.6.egg\n",
            "Searching for tokenizers==0.4.2\n",
            "Reading https://pypi.org/simple/tokenizers/\n",
            "Downloading https://files.pythonhosted.org/packages/2e/0a/096a279ee20a206a58ba9af3251c7271fb9493bed3bf29bfe4c58fcbfe4c/tokenizers-0.4.2-cp36-cp36m-manylinux1_x86_64.whl#sha256=da8e1593ef2a73cb0d2ebaf06183e8acd304ef1a272c526884a686ded9cf4d27\n",
            "Best match: tokenizers 0.4.2\n",
            "Processing tokenizers-0.4.2-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Installing tokenizers-0.4.2-cp36-cp36m-manylinux1_x86_64.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding tokenizers 0.4.2 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/tokenizers-0.4.2-py3.6-linux-x86_64.egg\n",
            "Searching for sphinx-autodoc-typehints==1.10.3\n",
            "Reading https://pypi.org/simple/sphinx-autodoc-typehints/\n",
            "Downloading https://files.pythonhosted.org/packages/00/83/87b8890a93b3994b49960716009c1effb6f7a1fef3a1ec553fda2a7c84de/sphinx_autodoc_typehints-1.10.3-py3-none-any.whl#sha256=27c9e6ef4f4451766ab8d08b2d8520933b97beb21c913f3df9ab2e59b56e6c6c\n",
            "Best match: sphinx-autodoc-typehints 1.10.3\n",
            "Processing sphinx_autodoc_typehints-1.10.3-py3-none-any.whl\n",
            "Installing sphinx_autodoc_typehints-1.10.3-py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding sphinx-autodoc-typehints 1.10.3 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/sphinx_autodoc_typehints-1.10.3-py3.6.egg\n",
            "Searching for sphinx_rtd_theme==0.4.3\n",
            "Reading https://pypi.org/simple/sphinx_rtd_theme/\n",
            "Downloading https://files.pythonhosted.org/packages/60/b4/4df37087a1d36755e3a3bfd2a30263f358d2dea21938240fa02313d45f51/sphinx_rtd_theme-0.4.3-py2.py3-none-any.whl#sha256=00cf895504a7895ee433807c62094cf1e95f065843bf3acd17037c3e9a2becd4\n",
            "Best match: sphinx-rtd-theme 0.4.3\n",
            "Processing sphinx_rtd_theme-0.4.3-py2.py3-none-any.whl\n",
            "Installing sphinx_rtd_theme-0.4.3-py2.py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding sphinx-rtd-theme 0.4.3 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/sphinx_rtd_theme-0.4.3-py3.6.egg\n",
            "Searching for Sphinx==2.2.0\n",
            "Reading https://pypi.org/simple/Sphinx/\n",
            "Downloading https://files.pythonhosted.org/packages/8e/4c/95a21788db2e1653e931420f561015a0bbc9bd4660c4520467ab9e733eb2/Sphinx-2.2.0-py3-none-any.whl#sha256=839a3ed6f6b092bb60f492024489cc9e6991360fb9f52ed6361acd510d261069\n",
            "Best match: Sphinx 2.2.0\n",
            "Processing Sphinx-2.2.0-py3-none-any.whl\n",
            "Installing Sphinx-2.2.0-py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding Sphinx 2.2.0 to easy-install.pth file\n",
            "Installing sphinx-apidoc script to /usr/local/bin\n",
            "Installing sphinx-autogen script to /usr/local/bin\n",
            "Installing sphinx-build script to /usr/local/bin\n",
            "Installing sphinx-quickstart script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/Sphinx-2.2.0-py3.6.egg\n",
            "Searching for sh==1.12.14\n",
            "Reading https://pypi.org/simple/sh/\n",
            "Downloading https://files.pythonhosted.org/packages/4a/22/17b22ef5b049f12080f5815c41bf94de3c229217609e469001a8f80c1b3d/sh-1.12.14-py2.py3-none-any.whl#sha256=ae3258c5249493cebe73cb4e18253a41ed69262484bad36fdb3efcb8ad8870bb\n",
            "Best match: sh 1.12.14\n",
            "Processing sh-1.12.14-py2.py3-none-any.whl\n",
            "Installing sh-1.12.14-py2.py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding sh 1.12.14 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/sh-1.12.14-py3.6.egg\n",
            "Searching for requests-mock==1.7.0\n",
            "Reading https://pypi.org/simple/requests-mock/\n",
            "Downloading https://files.pythonhosted.org/packages/8c/f1/66c54a412543b29454102ae74b1454fce2d307b1c36e6bd2e9818394df88/requests_mock-1.7.0-py2.py3-none-any.whl#sha256=510df890afe08d36eca5bb16b4aa6308a6f85e3159ad3013bac8b9de7bd5a010\n",
            "Best match: requests-mock 1.7.0\n",
            "Processing requests_mock-1.7.0-py2.py3-none-any.whl\n",
            "Installing requests_mock-1.7.0-py2.py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding requests-mock 1.7.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/requests_mock-1.7.0-py3.6.egg\n",
            "Searching for requests==2.22.0\n",
            "Reading https://pypi.org/simple/requests/\n",
            "Downloading https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl#sha256=9cf5292fcd0f598c671cfc1e0d7d1a7f13bb8085e9a590f48c010551dc6c4b31\n",
            "Best match: requests 2.22.0\n",
            "Processing requests-2.22.0-py2.py3-none-any.whl\n",
            "Installing requests-2.22.0-py2.py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding requests 2.22.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/requests-2.22.0-py3.6.egg\n",
            "Searching for recommonmark==0.6.0\n",
            "Reading https://pypi.org/simple/recommonmark/\n",
            "Downloading https://files.pythonhosted.org/packages/94/de/334aaf73df8c0e77fb07f883d1e274344526196c137ef3479cb5e5aef086/recommonmark-0.6.0-py2.py3-none-any.whl#sha256=2ec4207a574289355d5b6ae4ae4abb29043346ca12cdd5f07d374dc5987d2852\n",
            "Best match: recommonmark 0.6.0\n",
            "Processing recommonmark-0.6.0-py2.py3-none-any.whl\n",
            "Installing recommonmark-0.6.0-py2.py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding recommonmark 0.6.0 to easy-install.pth file\n",
            "Installing cm2html script to /usr/local/bin\n",
            "Installing cm2latex script to /usr/local/bin\n",
            "Installing cm2man script to /usr/local/bin\n",
            "Installing cm2pseudoxml script to /usr/local/bin\n",
            "Installing cm2xetex script to /usr/local/bin\n",
            "Installing cm2xml script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/recommonmark-0.6.0-py3.6.egg\n",
            "Searching for regex==2019.8.19\n",
            "Reading https://pypi.org/simple/regex/\n",
            "Downloading https://files.pythonhosted.org/packages/6f/a6/99eeb5904ab763db87af4bd71d9b1dfdd9792681240657a4c0a599c10a81/regex-2019.08.19.tar.gz#sha256=587b62d48ca359d2d4f02d486f1f0aa9a20fbaf23a9d4198c4bed72ab2f6c849\n",
            "Best match: regex 2019.8.19\n",
            "Processing regex-2019.08.19.tar.gz\n",
            "Writing /tmp/easy_install-cpxotz0d/regex-2019.08.19/setup.cfg\n",
            "Running regex-2019.08.19/setup.py -q bdist_egg --dist-dir /tmp/easy_install-cpxotz0d/regex-2019.08.19/egg-dist-tmp-3u3hs7a_\n",
            "BASE_DIR is /tmp/easy_install-cpxotz0d/regex-2019.08.19\n",
            "/usr/local/lib/python3.6/dist-packages/setuptools/dist.py:454: UserWarning: Normalizing '2019.08.19' to '2019.8.19'\n",
            "  warnings.warn(tmpl.format(**locals()))\n",
            "\u001b[01m\u001b[Kregex_3/_regex.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kfolded_char_at\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kregex_3/_regex.c:10625:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kvariable ‘\u001b[01m\u001b[Kfolded_len\u001b[m\u001b[K’ set but not used [\u001b[01;35m\u001b[K-Wunused-but-set-variable\u001b[m\u001b[K]\n",
            "     int \u001b[01;35m\u001b[Kfolded_len\u001b[m\u001b[K;\n",
            "         \u001b[01;35m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kregex_3/_regex.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kfuzzy_match_group_fld\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kregex_3/_regex.c:11503:10:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kdata.new_text_pos\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
            "     if (!\u001b[01;35m\u001b[Krecord_fuzzy(state, data.fuzzy_type, data.new_text_pos - data.step)\u001b[m\u001b[K)\n",
            "          \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kregex_3/_regex.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kfuzzy_match_string_fld\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kregex_3/_regex.c:11270:10:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kdata.new_text_pos\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
            "     if (!\u001b[01;35m\u001b[Krecord_fuzzy(state, data.fuzzy_type, data.new_text_pos - data.step)\u001b[m\u001b[K)\n",
            "          \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kregex_3/_regex.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kbasic_match\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kregex_3/_regex.c:11608:10:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kdata.new_text_pos\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
            "     if (!\u001b[01;35m\u001b[Krecord_fuzzy(state, data.fuzzy_type, data.new_text_pos - data.step)\u001b[m\u001b[K)\n",
            "          \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kregex_3/_regex.c:11522:18:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K‘\u001b[01m\u001b[Kdata.new_text_pos\u001b[m\u001b[K’ was declared here\n",
            "     RE_FuzzyData \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K;\n",
            "                  \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kregex_3/_regex.c:11369:10:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kdata.new_text_pos\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
            "     if (!\u001b[01;35m\u001b[Krecord_fuzzy(state, data.fuzzy_type, data.new_text_pos - data.step)\u001b[m\u001b[K)\n",
            "          \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kregex_3/_regex.c:11288:18:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K‘\u001b[01m\u001b[Kdata.new_text_pos\u001b[m\u001b[K’ was declared here\n",
            "     RE_FuzzyData \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K;\n",
            "                  \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "regex.__pycache__._regex.cpython-36: module references __file__\n",
            "creating /usr/local/lib/python3.6/dist-packages/regex-2019.8.19-py3.6-linux-x86_64.egg\n",
            "Extracting regex-2019.8.19-py3.6-linux-x86_64.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding regex 2019.8.19 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/regex-2019.8.19-py3.6-linux-x86_64.egg\n",
            "Searching for pyzmq==18.1.0\n",
            "Reading https://pypi.org/simple/pyzmq/\n",
            "Downloading https://files.pythonhosted.org/packages/75/89/6f0ea51ffa9c2c00c0ab0460f137b16a5ab5b47e3b060c5b1fc9ca425836/pyzmq-18.1.0-cp36-cp36m-manylinux1_x86_64.whl#sha256=b645a49376547b3816433a7e2d2a99135c8e651e50497e7ecac3bd126e4bea16\n",
            "Best match: pyzmq 18.1.0\n",
            "Processing pyzmq-18.1.0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Installing pyzmq-18.1.0-cp36-cp36m-manylinux1_x86_64.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding pyzmq 18.1.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/pyzmq-18.1.0-py3.6-linux-x86_64.egg\n",
            "Searching for pyyaml==5.1\n",
            "Reading https://pypi.org/simple/pyyaml/\n",
            "Downloading https://files.pythonhosted.org/packages/9f/2c/9417b5c774792634834e730932745bc09a7d36754ca00acf1ccd1ac2594d/PyYAML-5.1.tar.gz#sha256=436bc774ecf7c103814098159fbb84c2715d25980175292c648f2da143909f95\n",
            "Best match: PyYAML 5.1\n",
            "Processing PyYAML-5.1.tar.gz\n",
            "Writing /tmp/easy_install-3kuimkb1/PyYAML-5.1/setup.cfg\n",
            "Running PyYAML-5.1/setup.py -q bdist_egg --dist-dir /tmp/easy_install-3kuimkb1/PyYAML-5.1/egg-dist-tmp-5tpvobll\n",
            "In file included from \u001b[01m\u001b[Kext/_yaml.c:591:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Kext/_yaml.h:2:10:\u001b[m\u001b[K \u001b[01;31m\u001b[Kfatal error: \u001b[m\u001b[Kyaml.h: No such file or directory\n",
            " #include \u001b[01;31m\u001b[K<yaml.h>\u001b[m\u001b[K\n",
            "          \u001b[01;31m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "compilation terminated.\n",
            "Error compiling module, falling back to pure Python\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "Moving PyYAML-5.1-py3.6-linux-x86_64.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding PyYAML 5.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/PyYAML-5.1-py3.6-linux-x86_64.egg\n",
            "Searching for py-rouge==1.1\n",
            "Reading https://pypi.org/simple/py-rouge/\n",
            "Downloading https://files.pythonhosted.org/packages/9c/1d/0bdbaf559fb7afe32308ebc84a2028600988212d7eb7fb9f69c4e829e4a0/py_rouge-1.1-py3-none-any.whl#sha256=9ae2a859a9edc6d25f3908e48706f7d82d6e78ea18954560c4cb21897dc1d270\n",
            "Best match: py-rouge 1.1\n",
            "Processing py_rouge-1.1-py3-none-any.whl\n",
            "Installing py_rouge-1.1-py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding py-rouge 1.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/py_rouge-1.1-py3.6.egg\n",
            "Searching for py-gfm==0.1.4\n",
            "Reading https://pypi.org/simple/py-gfm/\n",
            "Downloading https://files.pythonhosted.org/packages/21/e0/be291e07b5e72e83285e4c0caf8060db0ab8d26f60bda254651e41493652/py_gfm-0.1.4-py2.py3-none-any.whl#sha256=d873541bcae194cc3b5053858719668834d3f1829342f0566ab3a48d0d744d58\n",
            "Best match: py-gfm 0.1.4\n",
            "Processing py_gfm-0.1.4-py2.py3-none-any.whl\n",
            "Installing py_gfm-0.1.4-py2.py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding py-gfm 0.1.4 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/py_gfm-0.1.4-py3.6.egg\n",
            "Searching for pexpect==4.7.0\n",
            "Reading https://pypi.org/simple/pexpect/\n",
            "Downloading https://files.pythonhosted.org/packages/0e/3e/377007e3f36ec42f1b84ec322ee12141a9e10d808312e5738f52f80a232c/pexpect-4.7.0-py2.py3-none-any.whl#sha256=2094eefdfcf37a1fdbfb9aa090862c1a4878e5c7e0e7e7088bdb511c558e5cd1\n",
            "Best match: pexpect 4.7.0\n",
            "Processing pexpect-4.7.0-py2.py3-none-any.whl\n",
            "Installing pexpect-4.7.0-py2.py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding pexpect 4.7.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/pexpect-4.7.0-py3.6.egg\n",
            "Searching for pytest==5.3.2\n",
            "Reading https://pypi.org/simple/pytest/\n",
            "Downloading https://files.pythonhosted.org/packages/19/cf/711f1d887cb92c5155c9a1eb338f1b5d2411b50e4492a3b20e4a188a22b2/pytest-5.3.2-py3-none-any.whl#sha256=e41d489ff43948babd0fad7ad5e49b8735d5d55e26628a58673c39ff61d95de4\n",
            "Best match: pytest 5.3.2\n",
            "Processing pytest-5.3.2-py3-none-any.whl\n",
            "Installing pytest-5.3.2-py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding pytest 5.3.2 to easy-install.pth file\n",
            "Installing py.test script to /usr/local/bin\n",
            "Installing pytest script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/pytest-5.3.2-py3.6.egg\n",
            "Searching for nltk==3.4.5\n",
            "Reading https://pypi.org/simple/nltk/\n",
            "Downloading https://files.pythonhosted.org/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip#sha256=bed45551259aa2101381bbdd5df37d44ca2669c5c3dad72439fa459b29137d94\n",
            "Best match: nltk 3.4.5\n",
            "Processing nltk-3.4.5.zip\n",
            "Writing /tmp/easy_install-8gndbplm/nltk-3.4.5/setup.cfg\n",
            "Running nltk-3.4.5/setup.py -q bdist_egg --dist-dir /tmp/easy_install-8gndbplm/nltk-3.4.5/egg-dist-tmp-v_xu7x_j\n",
            "warning: no files found matching 'README.txt'\n",
            "warning: no files found matching 'Makefile' under directory '*.txt'\n",
            "warning: no previously-included files matching '*~' found anywhere in distribution\n",
            "creating /usr/local/lib/python3.6/dist-packages/nltk-3.4.5-py3.6.egg\n",
            "Extracting nltk-3.4.5-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding nltk 3.4.5 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/nltk-3.4.5-py3.6.egg\n",
            "Searching for GitPython==3.0.3\n",
            "Reading https://pypi.org/simple/GitPython/\n",
            "Downloading https://files.pythonhosted.org/packages/ff/f8/05f58bd7852dad7edcf70a8de953b4fa39f61cdc13812ae62118be6ffa23/GitPython-3.0.3-py3-none-any.whl#sha256=6e97b9f0954807f30c2dd8e3165731ed6c477a1b365f194b69d81d7940a08332\n",
            "Best match: GitPython 3.0.3\n",
            "Processing GitPython-3.0.3-py3-none-any.whl\n",
            "Installing GitPython-3.0.3-py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding GitPython 3.0.3 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/GitPython-3.0.3-py3.6.egg\n",
            "Searching for gitdb2==2.0.5\n",
            "Reading https://pypi.org/simple/gitdb2/\n",
            "Downloading https://files.pythonhosted.org/packages/da/30/a407568aa8d8f25db817cf50121a958722f3fc5f87e3a6fba1f40c0633e3/gitdb2-2.0.5-py2.py3-none-any.whl#sha256=e3a0141c5f2a3f635c7209d56c496ebe1ad35da82fe4d3ec4aaa36278d70648a\n",
            "Best match: gitdb2 2.0.5\n",
            "Processing gitdb2-2.0.5-py2.py3-none-any.whl\n",
            "Installing gitdb2-2.0.5-py2.py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding gitdb2 2.0.5 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/gitdb2-2.0.5-py3.6.egg\n",
            "Searching for flake8-bugbear==19.8.0\n",
            "Reading https://pypi.org/simple/flake8-bugbear/\n",
            "Downloading https://files.pythonhosted.org/packages/9f/f8/170861859fb8ae97923b4fc28501dd25209925e25face836562d3e3f5ea2/flake8_bugbear-19.8.0-py35.py36.py37-none-any.whl#sha256=ded4d282778969b5ab5530ceba7aa1a9f1b86fa7618fc96a19a1d512331640f8\n",
            "Best match: flake8-bugbear 19.8.0\n",
            "Processing flake8_bugbear-19.8.0-py35.py36.py37-none-any.whl\n",
            "Installing flake8_bugbear-19.8.0-py35.py36.py37-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding flake8-bugbear 19.8.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/flake8_bugbear-19.8.0-py3.6.egg\n",
            "Searching for flake8==3.7.8\n",
            "Reading https://pypi.org/simple/flake8/\n",
            "Downloading https://files.pythonhosted.org/packages/26/de/3f815a99d86eb10464ea7bd6059c0172c7ca97d4bdcfca41051b388a653b/flake8-3.7.8-py2.py3-none-any.whl#sha256=8e9dfa3cecb2400b3738a42c54c3043e821682b9c840b0448c0503f781130696\n",
            "Best match: flake8 3.7.8\n",
            "Processing flake8-3.7.8-py2.py3-none-any.whl\n",
            "Installing flake8-3.7.8-py2.py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding flake8 3.7.8 to easy-install.pth file\n",
            "Installing flake8 script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/flake8-3.7.8-py3.6.egg\n",
            "Searching for docformatter==1.3.0\n",
            "Reading https://pypi.org/simple/docformatter/\n",
            "Downloading https://files.pythonhosted.org/packages/35/52/41c0152a44873c8f11f0f9fe21b680588ae0e2b20e4a0a9b4812f8decbdc/docformatter-1.3.tar.gz#sha256=c68c8db0952d7ec6423581915fde3f23d4be5eccc11eb28a3415b5cd0a1e4f73\n",
            "Best match: docformatter 1.3\n",
            "Processing docformatter-1.3.tar.gz\n",
            "Writing /tmp/easy_install-bk70yci3/docformatter-1.3/setup.cfg\n",
            "Running docformatter-1.3/setup.py -q bdist_egg --dist-dir /tmp/easy_install-bk70yci3/docformatter-1.3/egg-dist-tmp-s1_o1be9\n",
            "warning: no previously-included files found matching '.pre-commit-hooks.yaml'\n",
            "warning: no previously-included files found matching '.travis.yml'\n",
            "warning: no previously-included files found matching 'Makefile'\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "Moving docformatter-1.3-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding docformatter 1.3 to easy-install.pth file\n",
            "Installing docformatter script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/docformatter-1.3-py3.6.egg\n",
            "Searching for emoji==0.5.4\n",
            "Reading https://pypi.org/simple/emoji/\n",
            "Downloading https://files.pythonhosted.org/packages/40/8d/521be7f0091fe0f2ae690cc044faf43e3445e0ff33c574eae752dd7e39fa/emoji-0.5.4.tar.gz#sha256=60652d3a2dcee5b8af8acb097c31776fb6d808027aeb7221830f72cdafefc174\n",
            "Best match: emoji 0.5.4\n",
            "Processing emoji-0.5.4.tar.gz\n",
            "Writing /tmp/easy_install-t5fot5ig/emoji-0.5.4/setup.cfg\n",
            "Running emoji-0.5.4/setup.py -q bdist_egg --dist-dir /tmp/easy_install-t5fot5ig/emoji-0.5.4/egg-dist-tmp-59b8d_o7\n",
            "Moving emoji-0.5.4-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding emoji 0.5.4 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/emoji-0.5.4-py3.6.egg\n",
            "Searching for docutils==0.14\n",
            "Reading https://pypi.org/simple/docutils/\n",
            "Downloading https://files.pythonhosted.org/packages/36/fa/08e9e6e0e3cbd1d362c3bbee8d01d0aedb2155c4ac112b19ef3cae8eed8d/docutils-0.14-py3-none-any.whl#sha256=02aec4bd92ab067f6ff27a38a38a41173bf01bed8f89157768c1573f53e474a6\n",
            "Best match: docutils 0.14\n",
            "Processing docutils-0.14-py3-none-any.whl\n",
            "Installing docutils-0.14-py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding docutils 0.14 to easy-install.pth file\n",
            "Installing rst2latex.py script to /usr/local/bin\n",
            "Installing rst2man.py script to /usr/local/bin\n",
            "Installing rst2s5.py script to /usr/local/bin\n",
            "Installing rst2xetex.py script to /usr/local/bin\n",
            "Installing rst2xml.py script to /usr/local/bin\n",
            "Installing rst2pseudoxml.py script to /usr/local/bin\n",
            "Installing rst2odt.py script to /usr/local/bin\n",
            "Installing rst2odt_prepstyles.py script to /usr/local/bin\n",
            "Installing rst2html.py script to /usr/local/bin\n",
            "Installing rst2html5.py script to /usr/local/bin\n",
            "Installing rst2html4.py script to /usr/local/bin\n",
            "Installing rstpep2html.py script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/docutils-0.14-py3.6.egg\n",
            "Searching for botocore==1.12.246\n",
            "Reading https://pypi.org/simple/botocore/\n",
            "Downloading https://files.pythonhosted.org/packages/6d/22/398af6ea8d5c6bac57154442068613df74e7adbf255417c6894ef49fda42/botocore-1.12.246-py2.py3-none-any.whl#sha256=6dcc121be4917cc731577a2ddff67b89cee6a4b0ec30241ce207a80a0d41990a\n",
            "Best match: botocore 1.12.246\n",
            "Processing botocore-1.12.246-py2.py3-none-any.whl\n",
            "Installing botocore-1.12.246-py2.py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding botocore 1.12.246 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/botocore-1.12.246-py3.6.egg\n",
            "Searching for boto3==1.9.246\n",
            "Reading https://pypi.org/simple/boto3/\n",
            "Downloading https://files.pythonhosted.org/packages/5b/cd/a888759c39670cac6b74027d3e3a93073ecb99135b1292d15bc2f3b6f90a/boto3-1.9.246-py2.py3-none-any.whl#sha256=9a84be232ff6432312c16b8e52cc5a01e6ff461cb9b50b3cafee24c6876a5012\n",
            "Best match: boto3 1.9.246\n",
            "Processing boto3-1.9.246-py2.py3-none-any.whl\n",
            "Installing boto3-1.9.246-py2.py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding boto3 1.9.246 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/boto3-1.9.246-py3.6.egg\n",
            "Searching for sphinxcontrib-serializinghtml\n",
            "Reading https://pypi.org/simple/sphinxcontrib-serializinghtml/\n",
            "Downloading https://files.pythonhosted.org/packages/9a/ca/bfad79b79b3821d0c6361c431f0ef4aec16ee248338b2c2013008b34d345/sphinxcontrib_serializinghtml-1.1.4-py2.py3-none-any.whl#sha256=f242a81d423f59617a8e5cf16f5d4d74e28ee9a66f9e5b637a18082991db5a9a\n",
            "Best match: sphinxcontrib-serializinghtml 1.1.4\n",
            "Processing sphinxcontrib_serializinghtml-1.1.4-py2.py3-none-any.whl\n",
            "Installing sphinxcontrib_serializinghtml-1.1.4-py2.py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding sphinxcontrib-serializinghtml 1.1.4 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/sphinxcontrib_serializinghtml-1.1.4-py3.6.egg\n",
            "Searching for sphinxcontrib-qthelp\n",
            "Reading https://pypi.org/simple/sphinxcontrib-qthelp/\n",
            "Downloading https://files.pythonhosted.org/packages/2b/14/05f9206cf4e9cfca1afb5fd224c7cd434dcc3a433d6d9e4e0264d29c6cdb/sphinxcontrib_qthelp-1.0.3-py2.py3-none-any.whl#sha256=bd9fc24bcb748a8d51fd4ecaade681350aa63009a347a8c14e637895444dfab6\n",
            "Best match: sphinxcontrib-qthelp 1.0.3\n",
            "Processing sphinxcontrib_qthelp-1.0.3-py2.py3-none-any.whl\n",
            "Installing sphinxcontrib_qthelp-1.0.3-py2.py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding sphinxcontrib-qthelp 1.0.3 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/sphinxcontrib_qthelp-1.0.3-py3.6.egg\n",
            "Searching for sphinxcontrib-jsmath\n",
            "Reading https://pypi.org/simple/sphinxcontrib-jsmath/\n",
            "Downloading https://files.pythonhosted.org/packages/c2/42/4c8646762ee83602e3fb3fbe774c2fac12f317deb0b5dbeeedd2d3ba4b77/sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl#sha256=2ec2eaebfb78f3f2078e73666b1415417a116cc848b72e5172e596c871103178\n",
            "Best match: sphinxcontrib-jsmath 1.0.1\n",
            "Processing sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl\n",
            "Installing sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding sphinxcontrib-jsmath 1.0.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/sphinxcontrib_jsmath-1.0.1-py3.6.egg\n",
            "Searching for sphinxcontrib-htmlhelp\n",
            "Reading https://pypi.org/simple/sphinxcontrib-htmlhelp/\n",
            "Downloading https://files.pythonhosted.org/packages/36/62/8222554b29b3acde8420128d6d3999c5904d40922ef4b6ccb370e2be7421/sphinxcontrib_htmlhelp-1.0.3-py2.py3-none-any.whl#sha256=3c0bc24a2c41e340ac37c85ced6dafc879ab485c095b1d65d2461ac2f7cca86f\n",
            "Best match: sphinxcontrib-htmlhelp 1.0.3\n",
            "Processing sphinxcontrib_htmlhelp-1.0.3-py2.py3-none-any.whl\n",
            "Installing sphinxcontrib_htmlhelp-1.0.3-py2.py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding sphinxcontrib-htmlhelp 1.0.3 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/sphinxcontrib_htmlhelp-1.0.3-py3.6.egg\n",
            "Searching for sphinxcontrib-devhelp\n",
            "Reading https://pypi.org/simple/sphinxcontrib-devhelp/\n",
            "Downloading https://files.pythonhosted.org/packages/c5/09/5de5ed43a521387f18bdf5f5af31d099605c992fd25372b2b9b825ce48ee/sphinxcontrib_devhelp-1.0.2-py2.py3-none-any.whl#sha256=8165223f9a335cc1af7ffe1ed31d2871f325254c0423bc0c4c7cd1c1e4734a2e\n",
            "Best match: sphinxcontrib-devhelp 1.0.2\n",
            "Processing sphinxcontrib_devhelp-1.0.2-py2.py3-none-any.whl\n",
            "Installing sphinxcontrib_devhelp-1.0.2-py2.py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding sphinxcontrib-devhelp 1.0.2 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/sphinxcontrib_devhelp-1.0.2-py3.6.egg\n",
            "Searching for sphinxcontrib-applehelp\n",
            "Reading https://pypi.org/simple/sphinxcontrib-applehelp/\n",
            "Downloading https://files.pythonhosted.org/packages/dc/47/86022665a9433d89a66f5911b558ddff69861766807ba685de2e324bd6ed/sphinxcontrib_applehelp-1.0.2-py2.py3-none-any.whl#sha256=806111e5e962be97c29ec4c1e7fe277bfd19e9652fb1a4392105b43e01af885a\n",
            "Best match: sphinxcontrib-applehelp 1.0.2\n",
            "Processing sphinxcontrib_applehelp-1.0.2-py2.py3-none-any.whl\n",
            "Installing sphinxcontrib_applehelp-1.0.2-py2.py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding sphinxcontrib-applehelp 1.0.2 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/sphinxcontrib_applehelp-1.0.2-py3.6.egg\n",
            "Searching for idna<2.9,>=2.5\n",
            "Reading https://pypi.org/simple/idna/\n",
            "Downloading https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl#sha256=ea8b7f6188e6fa117537c3df7da9fc686d485087abf6ac197f9c46432f7e4a3c\n",
            "Best match: idna 2.8\n",
            "Processing idna-2.8-py2.py3-none-any.whl\n",
            "Installing idna-2.8-py2.py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding idna 2.8 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/idna-2.8-py3.6.egg\n",
            "Searching for commonmark>=0.8.1\n",
            "Reading https://pypi.org/simple/commonmark/\n",
            "Downloading https://files.pythonhosted.org/packages/b1/92/dfd892312d822f36c55366118b95d914e5f16de11044a27cf10a7d71bbbf/commonmark-0.9.1-py2.py3-none-any.whl#sha256=da2f38c92590f83de410ba1a3cbceafbc74fee9def35f9251ba9a971d6d66fd9\n",
            "Best match: commonmark 0.9.1\n",
            "Processing commonmark-0.9.1-py2.py3-none-any.whl\n",
            "Installing commonmark-0.9.1-py2.py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding commonmark 0.9.1 to easy-install.pth file\n",
            "Installing cmark script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/commonmark-0.9.1-py3.6.egg\n",
            "Searching for markdown<3.0\n",
            "Reading https://pypi.org/simple/markdown/\n",
            "Downloading https://files.pythonhosted.org/packages/6d/7d/488b90f470b96531a3f5788cf12a93332f543dbab13c423a5e7ce96a0493/Markdown-2.6.11-py2.py3-none-any.whl#sha256=9ba587db9daee7ec761cfc656272be6aabe2ed300fece21208e4aab2e457bc8f\n",
            "Best match: Markdown 2.6.11\n",
            "Processing Markdown-2.6.11-py2.py3-none-any.whl\n",
            "Installing Markdown-2.6.11-py2.py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding Markdown 2.6.11 to easy-install.pth file\n",
            "Installing markdown_py script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/Markdown-2.6.11-py3.6.egg\n",
            "Searching for pluggy<1.0,>=0.12\n",
            "Reading https://pypi.org/simple/pluggy/\n",
            "Downloading https://files.pythonhosted.org/packages/a0/28/85c7aa31b80d150b772fbe4a229487bc6644da9ccb7e427dd8cc60cb8a62/pluggy-0.13.1-py2.py3-none-any.whl#sha256=966c145cd83c96502c3c3868f50408687b38434af77734af1e9ca461a4081d2d\n",
            "Best match: pluggy 0.13.1\n",
            "Processing pluggy-0.13.1-py2.py3-none-any.whl\n",
            "Installing pluggy-0.13.1-py2.py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding pluggy 0.13.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/pluggy-0.13.1-py3.6.egg\n",
            "Searching for smmap2>=2.0.0\n",
            "Reading https://pypi.org/simple/smmap2/\n",
            "Downloading https://files.pythonhosted.org/packages/3e/11/2dae3df2f19c43e156cce8e02c0080b46821faf816b839a2023ef7b6b84f/smmap2-3.0.1-py3-none-any.whl#sha256=0cb6ea470b1ad9a65a02ca7f4c7ae601861f7dd24a43812ca51cfca2892bb524\n",
            "Best match: smmap2 3.0.1\n",
            "Processing smmap2-3.0.1-py3-none-any.whl\n",
            "Installing smmap2-3.0.1-py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding smmap2 3.0.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/smmap2-3.0.1-py3.6.egg\n",
            "Searching for pyflakes<2.2.0,>=2.1.0\n",
            "Reading https://pypi.org/simple/pyflakes/\n",
            "Downloading https://files.pythonhosted.org/packages/84/f2/ed0ffb887f8138a8fe5a621b8c0bb9598bfb3989e029f6c6a85ee66628ee/pyflakes-2.1.1-py2.py3-none-any.whl#sha256=17dbeb2e3f4d772725c777fabc446d5634d1038f234e77343108ce445ea69ce0\n",
            "Best match: pyflakes 2.1.1\n",
            "Processing pyflakes-2.1.1-py2.py3-none-any.whl\n",
            "Installing pyflakes-2.1.1-py2.py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding pyflakes 2.1.1 to easy-install.pth file\n",
            "Installing pyflakes script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/pyflakes-2.1.1-py3.6.egg\n",
            "Searching for pycodestyle<2.6.0,>=2.5.0\n",
            "Reading https://pypi.org/simple/pycodestyle/\n",
            "Downloading https://files.pythonhosted.org/packages/0e/0c/04a353e104d2f324f8ee5f4b32012618c1c86dd79e52a433b64fceed511b/pycodestyle-2.5.0-py2.py3-none-any.whl#sha256=95a2219d12372f05704562a14ec30bc76b05a5b297b21a5dfe3f6fac3491ae56\n",
            "Best match: pycodestyle 2.5.0\n",
            "Processing pycodestyle-2.5.0-py2.py3-none-any.whl\n",
            "Installing pycodestyle-2.5.0-py2.py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding pycodestyle 2.5.0 to easy-install.pth file\n",
            "Installing pycodestyle script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/pycodestyle-2.5.0-py3.6.egg\n",
            "Searching for mccabe<0.7.0,>=0.6.0\n",
            "Reading https://pypi.org/simple/mccabe/\n",
            "Downloading https://files.pythonhosted.org/packages/87/89/479dc97e18549e21354893e4ee4ef36db1d237534982482c3681ee6e7b57/mccabe-0.6.1-py2.py3-none-any.whl#sha256=ab8a6258860da4b6677da4bd2fe5dc2c659cff31b3ee4f7f5d64e79735b80d42\n",
            "Best match: mccabe 0.6.1\n",
            "Processing mccabe-0.6.1-py2.py3-none-any.whl\n",
            "Installing mccabe-0.6.1-py2.py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding mccabe 0.6.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/mccabe-0.6.1-py3.6.egg\n",
            "Searching for untokenize\n",
            "Reading https://pypi.org/simple/untokenize/\n",
            "Downloading https://files.pythonhosted.org/packages/f7/46/e7cea8159199096e1df52da20a57a6665da80c37fb8aeb848a3e47442c32/untokenize-0.1.1.tar.gz#sha256=3865dbbbb8efb4bb5eaa72f1be7f3e0be00ea8b7f125c69cbd1f5fda926f37a2\n",
            "Best match: untokenize 0.1.1\n",
            "Processing untokenize-0.1.1.tar.gz\n",
            "Writing /tmp/easy_install-iwaxfktr/untokenize-0.1.1/setup.cfg\n",
            "Running untokenize-0.1.1/setup.py -q bdist_egg --dist-dir /tmp/easy_install-iwaxfktr/untokenize-0.1.1/egg-dist-tmp-909dog9r\n",
            "warning: no previously-included files found matching '.travis.yml'\n",
            "warning: no previously-included files found matching 'Makefile'\n",
            "warning: no previously-included files found matching 'test_acid.py'\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "Moving untokenize-0.1.1-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding untokenize 0.1.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/untokenize-0.1.1-py3.6.egg\n",
            "Searching for s3transfer<0.3.0,>=0.2.0\n",
            "Reading https://pypi.org/simple/s3transfer/\n",
            "Downloading https://files.pythonhosted.org/packages/16/8a/1fc3dba0c4923c2a76e1ff0d52b305c44606da63f718d14d3231e21c51b0/s3transfer-0.2.1-py2.py3-none-any.whl#sha256=b780f2411b824cb541dbcd2c713d0cb61c7d1bcadae204cdddda2b35cef493ba\n",
            "Best match: s3transfer 0.2.1\n",
            "Processing s3transfer-0.2.1-py2.py3-none-any.whl\n",
            "Installing s3transfer-0.2.1-py2.py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding s3transfer 0.2.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/s3transfer-0.2.1-py3.6.egg\n",
            "Searching for smmap>=3.0.1\n",
            "Reading https://pypi.org/simple/smmap/\n",
            "Downloading https://files.pythonhosted.org/packages/b0/9a/4d409a6234eb940e6a78dfdfc66156e7522262f5f2fecca07dc55915952d/smmap-3.0.4-py2.py3-none-any.whl#sha256=54c44c197c819d5ef1991799a7e30b662d1e520f2ac75c9efbeb54a742214cf4\n",
            "Best match: smmap 3.0.4\n",
            "Processing smmap-3.0.4-py2.py3-none-any.whl\n",
            "Installing smmap-3.0.4-py2.py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding smmap 3.0.4 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/smmap-3.0.4-py3.6.egg\n",
            "Searching for scipy==1.4.1\n",
            "Best match: scipy 1.4.1\n",
            "Adding scipy 1.4.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for scikit-learn==0.22.2.post1\n",
            "Best match: scikit-learn 0.22.2.post1\n",
            "Adding scikit-learn 0.22.2.post1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Pillow==7.0.0\n",
            "Best match: Pillow 7.0.0\n",
            "Adding Pillow 7.0.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for numpy==1.18.4\n",
            "Best match: numpy 1.18.4\n",
            "Adding numpy 1.18.4 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.6 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for joblib==0.14.1\n",
            "Best match: joblib 0.14.1\n",
            "Adding joblib 0.14.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for h5py==2.10.0\n",
            "Best match: h5py 2.10.0\n",
            "Adding h5py 2.10.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for six==1.12.0\n",
            "Best match: six 1.12.0\n",
            "Adding six 1.12.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for snowballstemmer==2.0.0\n",
            "Best match: snowballstemmer 2.0.0\n",
            "Adding snowballstemmer 2.0.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for setuptools==46.3.0\n",
            "Best match: setuptools 46.3.0\n",
            "Adding setuptools 46.3.0 to easy-install.pth file\n",
            "Installing easy_install script to /usr/local/bin\n",
            "Installing easy_install-3.8 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for packaging==20.3\n",
            "Best match: packaging 20.3\n",
            "Adding packaging 20.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for imagesize==1.2.0\n",
            "Best match: imagesize 1.2.0\n",
            "Adding imagesize 1.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Babel==2.8.0\n",
            "Best match: Babel 2.8.0\n",
            "Adding Babel 2.8.0 to easy-install.pth file\n",
            "Installing pybabel script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for alabaster==0.7.12\n",
            "Best match: alabaster 0.7.12\n",
            "Adding alabaster 0.7.12 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Pygments==2.1.3\n",
            "Best match: Pygments 2.1.3\n",
            "Adding Pygments 2.1.3 to easy-install.pth file\n",
            "Installing pygmentize script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Jinja2==2.11.2\n",
            "Best match: Jinja2 2.11.2\n",
            "Adding Jinja2 2.11.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for urllib3==1.24.3\n",
            "Best match: urllib3 1.24.3\n",
            "Adding urllib3 1.24.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for chardet==3.0.4\n",
            "Best match: chardet 3.0.4\n",
            "Adding chardet 3.0.4 to easy-install.pth file\n",
            "Installing chardetect script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for certifi==2020.4.5.1\n",
            "Best match: certifi 2020.4.5.1\n",
            "Adding certifi 2020.4.5.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for ptyprocess==0.6.0\n",
            "Best match: ptyprocess 0.6.0\n",
            "Adding ptyprocess 0.6.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for wcwidth==0.1.9\n",
            "Best match: wcwidth 0.1.9\n",
            "Adding wcwidth 0.1.9 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for py==1.8.1\n",
            "Best match: py 1.8.1\n",
            "Adding py 1.8.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for more-itertools==8.2.0\n",
            "Best match: more-itertools 8.2.0\n",
            "Adding more-itertools 8.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for importlib-metadata==1.6.0\n",
            "Best match: importlib-metadata 1.6.0\n",
            "Adding importlib-metadata 1.6.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for attrs==19.3.0\n",
            "Best match: attrs 19.3.0\n",
            "Adding attrs 19.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for entrypoints==0.3\n",
            "Best match: entrypoints 0.3\n",
            "Adding entrypoints 0.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for python-dateutil==2.8.1\n",
            "Best match: python-dateutil 2.8.1\n",
            "Adding python-dateutil 2.8.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for jmespath==0.9.5\n",
            "Best match: jmespath 0.9.5\n",
            "Adding jmespath 0.9.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for pyparsing==2.4.7\n",
            "Best match: pyparsing 2.4.7\n",
            "Adding pyparsing 2.4.7 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for pytz==2018.9\n",
            "Best match: pytz 2018.9\n",
            "Adding pytz 2018.9 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for MarkupSafe==1.1.1\n",
            "Best match: MarkupSafe 1.1.1\n",
            "Adding MarkupSafe 1.1.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for zipp==3.1.0\n",
            "Best match: zipp 3.1.0\n",
            "Adding zipp 3.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Finished processing dependencies for parlai==0.1.20200516\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tpYptkopB9v",
        "colab_type": "text"
      },
      "source": [
        "## View a task & train a model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voG2qRUdqk90",
        "colab_type": "text"
      },
      "source": [
        "Let’s start by printing out the first few examples of the bAbI tasks, task 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UnMHB6AopXh",
        "colab_type": "code",
        "outputId": "01380bf8-fd5f-4095-877e-aaa01ee58f6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "!python /content/ParlAI/examples/display_data.py -t babi:task10k:1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[creating task(s): babi:task10k:1]\n",
            "[building data: /content/ParlAI/data/bAbI]\n",
            "[ downloading: http://parl.ai/downloads/babi/babi.tar.gz to /content/ParlAI/data/bAbI/babi.tar.gz ]\n",
            "Downloading babi.tar.gz: 100% 19.2M/19.2M [00:04<00:00, 4.56MB/s]\n",
            "[ Checksum Successful ]\n",
            "unpacking babi.tar.gz\n",
            "[loading fbdialog data:/content/ParlAI/data/bAbI/tasks_1-20_v1-2/en-valid-10k-nosf/qa1_train.txt]\n",
            "\u001b[1;31m- - - NEW EPISODE: babi:task10k:1 - - -\u001b[0;0m\n",
            "\u001b[0mMary moved to the bathroom.\n",
            "John went to the hallway.\n",
            "Where is Mary?\u001b[0;0m\n",
            "   \u001b[1;94mbathroom\u001b[0;0m\n",
            "\u001b[0mDaniel went back to the hallway.\n",
            "Sandra moved to the garden.\n",
            "Where is Daniel?\u001b[0;0m\n",
            "   \u001b[1;94mhallway\u001b[0;0m\n",
            "\u001b[0mJohn moved to the office.\n",
            "Sandra journeyed to the bathroom.\n",
            "Where is Daniel?\u001b[0;0m\n",
            "   \u001b[1;94mhallway\u001b[0;0m\n",
            "\u001b[0mMary moved to the hallway.\n",
            "Daniel travelled to the office.\n",
            "Where is Daniel?\u001b[0;0m\n",
            "   \u001b[1;94moffice\u001b[0;0m\n",
            "\u001b[0mJohn went back to the garden.\n",
            "John moved to the bedroom.\n",
            "Where is Sandra?\u001b[0;0m\n",
            "   \u001b[1;94mbathroom\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: babi:task10k:1 - - -\u001b[0;0m\n",
            "\u001b[0mMary went to the bedroom.\n",
            "John journeyed to the bathroom.\n",
            "Where is John?\u001b[0;0m\n",
            "   \u001b[1;94mbathroom\u001b[0;0m\n",
            "\u001b[0mSandra journeyed to the hallway.\n",
            "John journeyed to the garden.\n",
            "Where is Mary?\u001b[0;0m\n",
            "   \u001b[1;94mbedroom\u001b[0;0m\n",
            "\u001b[0mJohn journeyed to the bathroom.\n",
            "Sandra journeyed to the garden.\n",
            "Where is John?\u001b[0;0m\n",
            "   \u001b[1;94mbathroom\u001b[0;0m\n",
            "\u001b[0mSandra went back to the bedroom.\n",
            "Daniel travelled to the bathroom.\n",
            "Where is John?\u001b[0;0m\n",
            "   \u001b[1;94mbathroom\u001b[0;0m\n",
            "\u001b[0mJohn went to the office.\n",
            "Mary moved to the office.\n",
            "Where is Sandra?\u001b[0;0m\n",
            "   \u001b[1;94mbedroom\u001b[0;0m\n",
            "[ loaded 1800 episodes with a total of 9000 examples ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ygNMlJXqnSS",
        "colab_type": "text"
      },
      "source": [
        "Now let’s try to train a model on it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tstX_1fapbKr",
        "colab_type": "code",
        "outputId": "d4406b1d-f6f7-4f40-8923-c64c9106ec90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python /content/ParlAI/examples/train_model.py -t babi:task10k:1 -mf /tmp/babi_memnn -bs 1 -nt 4 -eps 5 -m memnn --no-cuda"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ building dictionary first... ]\n",
            "[ dictionary already built .]\n",
            "[ no model with opt yet at: /tmp/babi_memnn(.opt) ]\n",
            "Dictionary: loading dictionary from /tmp/babi_memnn.dict\n",
            "[ num words =  26 ]\n",
            "Total parameters: 46,080 (46,080 trainable)\n",
            "[creating task(s): babi:task10k:1]\n",
            "[loading fbdialog data:/content/ParlAI/data/bAbI/tasks_1-20_v1-2/en-valid-10k-nosf/qa1_train.txt]\n",
            "[ 4 threads initialized ]\n",
            "[ training... ]\n",
            "/content/ParlAI/parlai/core/torch_ranker_agent.py:710: UserWarning: [ Executing train mode with provided inline set of candidates ]\n",
            "  ''.format(mode)\n",
            "/content/ParlAI/parlai/core/torch_ranker_agent.py:710: UserWarning: [ Executing train mode with provided inline set of candidates ]\n",
            "  ''.format(mode)\n",
            "/content/ParlAI/parlai/core/torch_ranker_agent.py:710: UserWarning: [ Executing train mode with provided inline set of candidates ]\n",
            "  ''.format(mode)\n",
            "/content/ParlAI/parlai/core/torch_ranker_agent.py:710: UserWarning: [ Executing train mode with provided inline set of candidates ]\n",
            "  ''.format(mode)\n",
            "/content/ParlAI/parlai/core/torch_ranker_agent.py:470: UserWarning: Some training metrics are omitted for speed. Set the flag `--train-predict` to calculate train metrics.\n",
            "  \"Some training metrics are omitted for speed. Set the flag \"\n",
            "/content/ParlAI/parlai/core/torch_ranker_agent.py:470: UserWarning: Some training metrics are omitted for speed. Set the flag `--train-predict` to calculate train metrics.\n",
            "  \"Some training metrics are omitted for speed. Set the flag \"\n",
            "/content/ParlAI/parlai/core/torch_ranker_agent.py:470: UserWarning: Some training metrics are omitted for speed. Set the flag `--train-predict` to calculate train metrics.\n",
            "  \"Some training metrics are omitted for speed. Set the flag \"\n",
            "/content/ParlAI/parlai/core/torch_ranker_agent.py:470: UserWarning: Some training metrics are omitted for speed. Set the flag `--train-predict` to calculate train metrics.\n",
            "  \"Some training metrics are omitted for speed. Set the flag \"\n",
            "[ time:10.0s total_exs:2647 epochs:0.29 time_left:161.0s ]\n",
            "    clip  \\\n",
            "   .5561   \n",
            "    exs  \\\n",
            "   2647   \n",
            "    gnorm  \\\n",
            "    31.02   \n",
            "    lr  \\\n",
            "     1   \n",
            "    mean_loss  \\\n",
            "        1.525   \n",
            "    tpb  \\\n",
            "      1   \n",
            "    updates  \n",
            "       2647\n",
            "\n",
            "[ time:20.0s total_exs:5349 epochs:0.59 time_left:151.0s ]\n",
            "    clip  \\\n",
            "   .1336   \n",
            "    exs  \\\n",
            "   2702   \n",
            "    gnorm  \\\n",
            "     8.76   \n",
            "    lr  \\\n",
            "     1   \n",
            "    mean_loss  \\\n",
            "        .1780   \n",
            "    tpb  \\\n",
            "      1   \n",
            "    updates  \n",
            "       2702\n",
            "\n",
            "[ time:30.0s total_exs:8055 epochs:0.9 time_left:139.0s ]\n",
            "     clip  \\\n",
            "   .09497   \n",
            "    exs  \\\n",
            "   2706   \n",
            "    gnorm  \\\n",
            "    5.981   \n",
            "    lr  \\\n",
            "     1   \n",
            "    mean_loss  \\\n",
            "       .09296   \n",
            "    tpb  \\\n",
            "      1   \n",
            "    updates  \n",
            "       2706\n",
            "\n",
            "[ time:40.0s total_exs:10745 epochs:1.19 time_left:129.0s ]\n",
            "     clip  \\\n",
            "   .05911   \n",
            "    exs  \\\n",
            "   2690   \n",
            "    gnorm  \\\n",
            "    3.947   \n",
            "    lr  \\\n",
            "     1   \n",
            "    mean_loss  \\\n",
            "       .05562   \n",
            "    tpb  \\\n",
            "      1   \n",
            "    updates  \n",
            "       2690\n",
            "\n",
            "[ time:50.0s total_exs:13447 epochs:1.49 time_left:119.0s ]\n",
            "    clip  \\\n",
            "   .0544   \n",
            "    exs  \\\n",
            "   2702   \n",
            "    gnorm  \\\n",
            "    3.305   \n",
            "    lr  \\\n",
            "     1   \n",
            "    mean_loss  \\\n",
            "       .03663   \n",
            "    tpb  \\\n",
            "      1   \n",
            "    updates  \n",
            "       2702\n",
            "\n",
            "[ time:60.0s total_exs:16161 epochs:1.8 time_left:108.0s ]\n",
            "     clip  \\\n",
            "   .04053   \n",
            "    exs  \\\n",
            "   2714   \n",
            "    gnorm  \\\n",
            "    2.004   \n",
            "    lr  \\\n",
            "     1   \n",
            "    mean_loss  \\\n",
            "       .01861   \n",
            "    tpb  \\\n",
            "      1   \n",
            "    updates  \n",
            "       2714\n",
            "\n",
            "[ time:70.0s total_exs:18844 epochs:2.09 time_left:98.0s ]\n",
            "     clip  \\\n",
            "   .03541   \n",
            "    exs  \\\n",
            "   2683   \n",
            "    gnorm  \\\n",
            "    2.403   \n",
            "    lr  \\\n",
            "     1   \n",
            "    mean_loss  \\\n",
            "       .02801   \n",
            "    tpb  \\\n",
            "      1   \n",
            "    updates  \n",
            "       2683\n",
            "\n",
            "[ time:80.0s total_exs:21541 epochs:2.39 time_left:88.0s ]\n",
            "    clip  \\\n",
            "   .0241   \n",
            "    exs  \\\n",
            "   2697   \n",
            "    gnorm  \\\n",
            "    1.448   \n",
            "    lr  \\\n",
            "     1   \n",
            "    mean_loss  \\\n",
            "       .01565   \n",
            "    tpb  \\\n",
            "      1   \n",
            "    updates  \n",
            "       2697\n",
            "\n",
            "[ time:90.0s total_exs:24249 epochs:2.69 time_left:78.0s ]\n",
            "     clip  \\\n",
            "   .02253   \n",
            "    exs  \\\n",
            "   2708   \n",
            "    gnorm  \\\n",
            "    1.441   \n",
            "    lr  \\\n",
            "     1   \n",
            "    mean_loss  \\\n",
            "       .02224   \n",
            "    tpb  \\\n",
            "      1   \n",
            "    updates  \n",
            "       2708\n",
            "\n",
            "[ time:100.0s total_exs:26956 epochs:3.0 time_left:68.0s ]\n",
            "     clip  \\\n",
            "   .02106   \n",
            "    exs  \\\n",
            "   2707   \n",
            "    gnorm  \\\n",
            "      1.4   \n",
            "    lr  \\\n",
            "     1   \n",
            "    mean_loss  \\\n",
            "       .01508   \n",
            "    tpb  \\\n",
            "      1   \n",
            "    updates  \n",
            "       2707\n",
            "\n",
            "[ time:110.0s total_exs:29663 epochs:3.3 time_left:58.0s ]\n",
            "     clip  \\\n",
            "   .02216   \n",
            "    exs  \\\n",
            "   2707   \n",
            "    gnorm  \\\n",
            "    1.604   \n",
            "    lr  \\\n",
            "     1   \n",
            "    mean_loss  \\\n",
            "       .01214   \n",
            "    tpb  \\\n",
            "      1   \n",
            "    updates  \n",
            "       2707\n",
            "\n",
            "[ time:120.0s total_exs:32380 epochs:3.6 time_left:47.0s ]\n",
            "     clip  \\\n",
            "   .01067   \n",
            "    exs  \\\n",
            "   2717   \n",
            "    gnorm  \\\n",
            "    .8068   \n",
            "    lr  \\\n",
            "     1   \n",
            "    mean_loss  \\\n",
            "      .006241   \n",
            "    tpb  \\\n",
            "      1   \n",
            "    updates  \n",
            "       2717\n",
            "\n",
            "[ time:130.0s total_exs:35067 epochs:3.9 time_left:37.0s ]\n",
            "     clip  \\\n",
            "   .01675   \n",
            "    exs  \\\n",
            "   2687   \n",
            "    gnorm  \\\n",
            "    1.333   \n",
            "    lr  \\\n",
            "     1   \n",
            "    mean_loss  \\\n",
            "       .02189   \n",
            "    tpb  \\\n",
            "      1   \n",
            "    updates  \n",
            "       2687\n",
            "\n",
            "[ time:140.0s total_exs:37775 epochs:4.2 time_left:27.0s ]\n",
            "     clip  \\\n",
            "   .01404   \n",
            "    exs  \\\n",
            "   2708   \n",
            "    gnorm  \\\n",
            "    .6561   \n",
            "    lr  \\\n",
            "     1   \n",
            "    mean_loss  \\\n",
            "      .007127   \n",
            "    tpb  \\\n",
            "      1   \n",
            "    updates  \n",
            "       2707\n",
            "\n",
            "[ time:150.0s total_exs:40482 epochs:4.5 time_left:17.0s ]\n",
            "     clip  \\\n",
            "   .01552   \n",
            "    exs  \\\n",
            "   2707   \n",
            "    gnorm  \\\n",
            "    1.038   \n",
            "    lr  \\\n",
            "     1   \n",
            "    mean_loss  \\\n",
            "       .01228   \n",
            "    tpb  \\\n",
            "      1   \n",
            "    updates  \n",
            "       2707\n",
            "\n",
            "[ time:160.0s total_exs:43186 epochs:4.8 time_left:7.0s ]\n",
            "     clip  \\\n",
            "   .01479   \n",
            "    exs  \\\n",
            "   2704   \n",
            "    gnorm  \\\n",
            "    .8186   \n",
            "    lr  \\\n",
            "     1   \n",
            "    mean_loss  \\\n",
            "      .008927   \n",
            "    tpb  \\\n",
            "      1   \n",
            "    updates  \n",
            "       2704\n",
            "\n",
            "[ time:167.0s total_exs:45000 epochs:5.0 time_left:0s ]\n",
            "      clip  \\\n",
            "   .009923   \n",
            "    exs  \\\n",
            "   1814   \n",
            "    gnorm  \\\n",
            "    .5014   \n",
            "    lr  \\\n",
            "     1   \n",
            "    mean_loss  \\\n",
            "       .00183   \n",
            "    tpb  \\\n",
            "      1   \n",
            "    updates  \n",
            "       1814\n",
            "\n",
            "[ num_epochs completed:5.0 time elapsed:167.40034174919128s ]\n",
            "Dictionary: loading dictionary from /tmp/babi_memnn.dict\n",
            "[ num words =  26 ]\n",
            "Total parameters: 46,080 (46,080 trainable)\n",
            "Loading existing model parameters from /tmp/babi_memnn\n",
            "[creating task(s): babi:task10k:1]\n",
            "[loading fbdialog data:/content/ParlAI/data/bAbI/tasks_1-20_v1-2/en-valid-10k-nosf/qa1_valid.txt]\n",
            "[ 4 threads initialized ]\n",
            "[ running eval: valid ]\n",
            "/content/ParlAI/parlai/core/torch_ranker_agent.py:710: UserWarning: [ Executing eval mode with provided inline set of candidates ]\n",
            "  ''.format(mode)\n",
            "/content/ParlAI/parlai/core/torch_ranker_agent.py:710: UserWarning: [ Executing eval mode with provided inline set of candidates ]\n",
            "  ''.format(mode)\n",
            "/content/ParlAI/parlai/core/torch_ranker_agent.py:710: UserWarning: [ Executing eval mode with provided inline set of candidates ]\n",
            "  ''.format(mode)\n",
            "/content/ParlAI/parlai/core/torch_ranker_agent.py:710: UserWarning: [ Executing eval mode with provided inline set of candidates ]\n",
            "  ''.format(mode)\n",
            "[ eval completed in 2.52s ]\n",
            "valid:\n",
            "    accuracy  \\\n",
            "       .9990   \n",
            "     bleu-4  \\\n",
            "   9.99e-10   \n",
            "    exs  \\\n",
            "   1000   \n",
            "      f1  \\\n",
            "   .9990   \n",
            "    hits@1  \\\n",
            "     .9990   \n",
            "    hits@10  \\\n",
            "          1   \n",
            "    hits@100  \\\n",
            "           1   \n",
            "    hits@5  \\\n",
            "         1   \n",
            "      loss  \\\n",
            "   .001839   \n",
            "    lr  \\\n",
            "     1   \n",
            "     mrr  \\\n",
            "   .9995   \n",
            "    rank  \\\n",
            "   1.001   \n",
            "    tpb  \n",
            "      1\n",
            "\n",
            "[creating task(s): babi:task10k:1]\n",
            "[loading fbdialog data:/content/ParlAI/data/bAbI/tasks_1-20_v1-2/en-valid-10k-nosf/qa1_test.txt]\n",
            "[ 4 threads initialized ]\n",
            "[ running eval: test ]\n",
            "/content/ParlAI/parlai/core/torch_ranker_agent.py:710: UserWarning: [ Executing eval mode with provided inline set of candidates ]\n",
            "  ''.format(mode)\n",
            "/content/ParlAI/parlai/core/torch_ranker_agent.py:710: UserWarning: [ Executing eval mode with provided inline set of candidates ]\n",
            "  ''.format(mode)\n",
            "/content/ParlAI/parlai/core/torch_ranker_agent.py:710: UserWarning: [ Executing eval mode with provided inline set of candidates ]\n",
            "  ''.format(mode)\n",
            "/content/ParlAI/parlai/core/torch_ranker_agent.py:710: UserWarning: [ Executing eval mode with provided inline set of candidates ]\n",
            "  ''.format(mode)\n",
            "[ eval completed in 2.49s ]\n",
            "test:\n",
            "    accuracy  \\\n",
            "       .9990   \n",
            "     bleu-4  \\\n",
            "   9.99e-10   \n",
            "    exs  \\\n",
            "   1000   \n",
            "      f1  \\\n",
            "   .9990   \n",
            "    hits@1  \\\n",
            "     .9990   \n",
            "    hits@10  \\\n",
            "          1   \n",
            "    hits@100  \\\n",
            "           1   \n",
            "    hits@5  \\\n",
            "         1   \n",
            "      loss  \\\n",
            "   .001565   \n",
            "    lr  \\\n",
            "     1   \n",
            "     mrr  \\\n",
            "   .9995   \n",
            "    rank  \\\n",
            "   1.001   \n",
            "    tpb  \n",
            "      1\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBX97z-CrRdb",
        "colab_type": "text"
      },
      "source": [
        "Let’s print some of its predictions to make sure it’s working."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYY-xGFMqNKG",
        "colab_type": "code",
        "outputId": "3775e61d-e7b7-402e-ac03-f93729f3b8ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python /content/ParlAI/examples/display_model.py -t babi:task10k:1 -mf /tmp/babi_memnn -ecands vocab"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ optional arguments: ] \n",
            "[  display_ignore_fields:  ]\n",
            "[  num_examples: 10 ]\n",
            "[  verbose: False ]\n",
            "[ Main ParlAI Arguments: ] \n",
            "[  batchsize: 1 ]\n",
            "[  datapath: /content/ParlAI/data ]\n",
            "[  datatype: valid ]\n",
            "[  download_path: /content/ParlAI/downloads ]\n",
            "[  dynamic_batching: None ]\n",
            "[  hide_labels: False ]\n",
            "[  image_mode: raw ]\n",
            "[  init_opt: None ]\n",
            "[  multitask_weights: [1] ]\n",
            "[  numthreads: 1 ]\n",
            "[  show_advanced_args: False ]\n",
            "[  task: babi:task10k:1 ]\n",
            "[ ParlAI Model Arguments: ] \n",
            "[  dict_class: parlai.core.dict:DictionaryAgent ]\n",
            "[  init_model: None ]\n",
            "[  model: None ]\n",
            "[  model_file: /tmp/babi_memnn ]\n",
            "[ ParlAI Image Preprocessing Arguments: ] \n",
            "[  image_cropsize: 224 ]\n",
            "[  image_size: 256 ]\n",
            "[ MemNN Arguments: ] \n",
            "[  embedding_size: 128 ]\n",
            "[  hops: 3 ]\n",
            "[  memsize: 32 ]\n",
            "[  position_encoding: False ]\n",
            "[  time_features: True ]\n",
            "[ TorchAgent Arguments: ] \n",
            "[  add_p1_after_newln: True ]\n",
            "[  delimiter: \n",
            " ]\n",
            "[  embedding_projection: random ]\n",
            "[  embedding_type: random ]\n",
            "[  force_fp16_tokens: False ]\n",
            "[  fp16: False ]\n",
            "[  fp16_impl: apex ]\n",
            "[  gpu: -1 ]\n",
            "[  history_add_global_end_token: None ]\n",
            "[  history_size: -1 ]\n",
            "[  interactive_mode: False ]\n",
            "[  label_truncate: None ]\n",
            "[  no_cuda: False ]\n",
            "[  person_tokens: False ]\n",
            "[  rank_candidates: False ]\n",
            "[  split_lines: True ]\n",
            "[  text_truncate: None ]\n",
            "[  truncate: -1 ]\n",
            "[  use_reply: label ]\n",
            "[ Optimizer Arguments: ] \n",
            "[  adafactor_eps: (1e-30, 0.001) ]\n",
            "[  adam_eps: 1e-08 ]\n",
            "[  betas: (0.9, 0.999) ]\n",
            "[  gradient_clip: 0.1 ]\n",
            "[  learningrate: 1 ]\n",
            "[  momentum: 0 ]\n",
            "[  nesterov: True ]\n",
            "[  nus: (0.7,) ]\n",
            "[  optimizer: sgd ]\n",
            "[  weight_decay: None ]\n",
            "[ Learning Rate Scheduler: ] \n",
            "[  invsqrt_lr_decay_gamma: -1 ]\n",
            "[  lr_scheduler: reduceonplateau ]\n",
            "[  lr_scheduler_decay: 0.5 ]\n",
            "[  lr_scheduler_patience: 3 ]\n",
            "[  max_lr_steps: -1 ]\n",
            "[  update_freq: 1 ]\n",
            "[  warmup_rate: 0.0001 ]\n",
            "[  warmup_updates: -1 ]\n",
            "[ TorchRankerAgent: ] \n",
            "[  candidates: inline ]\n",
            "[  cap_num_predictions: 100 ]\n",
            "[  encode_candidate_vecs: True ]\n",
            "[  encode_candidate_vecs_batchsize: 256 ]\n",
            "[  eval_candidates: vocab ]\n",
            "[  fixed_candidate_vecs: reuse ]\n",
            "[  fixed_candidates_path: None ]\n",
            "[  ignore_bad_candidates: False ]\n",
            "[  inference: max ]\n",
            "[  init_model: None ]\n",
            "[  interactive_candidates: fixed ]\n",
            "[  rank_top_k: -1 ]\n",
            "[  repeat_blocking_heuristic: True ]\n",
            "[  return_cand_scores: False ]\n",
            "[  topk: 5 ]\n",
            "[  train_predict: False ]\n",
            "[ Dictionary Arguments: ] \n",
            "[  bpe_debug: False ]\n",
            "[  dict_endtoken: __end__ ]\n",
            "[  dict_file: None ]\n",
            "[  dict_initpath: None ]\n",
            "[  dict_language: english ]\n",
            "[  dict_lower: False ]\n",
            "[  dict_max_ngram_size: -1 ]\n",
            "[  dict_maxtokens: -1 ]\n",
            "[  dict_minfreq: 0 ]\n",
            "[  dict_nulltoken: __null__ ]\n",
            "[  dict_starttoken: __start__ ]\n",
            "[  dict_textfields: text,labels ]\n",
            "[  dict_tokenizer: re ]\n",
            "[  dict_unktoken: __unk__ ]\n",
            "[ BPEHelper Arguments: ] \n",
            "[  bpe_add_prefix_space: None ]\n",
            "[  bpe_merge: None ]\n",
            "[  bpe_vocab: None ]\n",
            "[ Current ParlAI commit: b49eba4519856f6ab83b869b168c6af99863df47 ]\n",
            "[ warning: overriding opt['eval_candidates'] to vocab (previously: inline )]\n",
            "Dictionary: loading dictionary from /tmp/babi_memnn.dict\n",
            "[ num words =  26 ]\n",
            "Total parameters: 46,080 (46,080 trainable)\n",
            "Loading existing model parameters from /tmp/babi_memnn\n",
            "[ Loaded fixed candidate set (n = 57) from vocabulary ]\n",
            "[ Encoding fixed candidates set from (1 batch(es) of up to 256) ]\n",
            "\r  0% 0/1 [00:00<?, ?it/s]\r100% 1/1 [00:00<00:00, 1490.51it/s]\n",
            "[creating task(s): babi:task10k:1]\n",
            "[loading fbdialog data:/content/ParlAI/data/bAbI/tasks_1-20_v1-2/en-valid-10k-nosf/qa1_valid.txt]\n",
            "/content/ParlAI/parlai/core/torch_ranker_agent.py:790: UserWarning: [ Executing eval mode with tokens from vocabulary as candidates. ]\n",
            "  ''.format(mode)\n",
            "[ Encoding fixed candidates set from (1 batch(es) of up to 256) ]\n",
            "\r  0% 0/1 [00:00<?, ?it/s]\r100% 1/1 [00:00<00:00, 3463.50it/s]\n",
            "\u001b[1;31m- - - NEW EPISODE: babi:task10k:1- - -\u001b[0;0m\n",
            "\u001b[0mSandra travelled to the office.\n",
            "Sandra went to the bathroom.\n",
            "Where is Sandra?\u001b[0;0m\n",
            "\u001b[1;94m    labels: bathroom\u001b[0;0m\n",
            "\u001b[0;95m     model: bathroom\u001b[0;0m\n",
            "\u001b[0mMary went to the bedroom.\n",
            "Daniel moved to the hallway.\n",
            "Where is Sandra?\u001b[0;0m\n",
            "\u001b[1;94m    labels: bathroom\u001b[0;0m\n",
            "\u001b[0;95m     model: bathroom\u001b[0;0m\n",
            "\u001b[0mJohn went to the garden.\n",
            "John travelled to the office.\n",
            "Where is Sandra?\u001b[0;0m\n",
            "\u001b[1;94m    labels: bathroom\u001b[0;0m\n",
            "\u001b[0;95m     model: bathroom\u001b[0;0m\n",
            "\u001b[0mDaniel journeyed to the bedroom.\n",
            "Daniel travelled to the hallway.\n",
            "Where is John?\u001b[0;0m\n",
            "\u001b[1;94m    labels: office\u001b[0;0m\n",
            "\u001b[0;95m     model: office\u001b[0;0m\n",
            "\u001b[0mJohn went to the bedroom.\n",
            "John travelled to the office.\n",
            "Where is Daniel?\u001b[0;0m\n",
            "\u001b[1;94m    labels: hallway\u001b[0;0m\n",
            "\u001b[0;95m     model: hallway\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: babi:task10k:1- - -\u001b[0;0m\n",
            "\u001b[0mSandra went back to the bathroom.\n",
            "Mary moved to the garden.\n",
            "Where is Mary?\u001b[0;0m\n",
            "\u001b[1;94m    labels: garden\u001b[0;0m\n",
            "\u001b[0;95m     model: garden\u001b[0;0m\n",
            "\u001b[0mMary went back to the hallway.\n",
            "Sandra went to the office.\n",
            "Where is Sandra?\u001b[0;0m\n",
            "\u001b[1;94m    labels: office\u001b[0;0m\n",
            "\u001b[0;95m     model: office\u001b[0;0m\n",
            "\u001b[0mJohn went back to the hallway.\n",
            "John travelled to the office.\n",
            "Where is Sandra?\u001b[0;0m\n",
            "\u001b[1;94m    labels: office\u001b[0;0m\n",
            "\u001b[0;95m     model: office\u001b[0;0m\n",
            "\u001b[0mSandra journeyed to the hallway.\n",
            "Daniel moved to the office.\n",
            "Where is John?\u001b[0;0m\n",
            "\u001b[1;94m    labels: office\u001b[0;0m\n",
            "\u001b[0;95m     model: office\u001b[0;0m\n",
            "\u001b[0mMary went to the office.\n",
            "Sandra went to the office.\n",
            "Where is John?\u001b[0;0m\n",
            "\u001b[1;94m    labels: office\u001b[0;0m\n",
            "\u001b[0;95m     model: office\u001b[0;0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ks9AXzmkrViT",
        "colab_type": "text"
      },
      "source": [
        "The “eval_labels” and “MemNN” lines should (usually) match!\n",
        "\n",
        "Let’s try asking the model a question ourselves."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQRssV6nrWNi",
        "colab_type": "code",
        "outputId": "23de0625-074c-40fd-8d56-76097ff3390c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python /content/ParlAI/examples/interactive.py -mf /tmp/babi_memnn -ecands vocab"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ warning: overriding opt['eval_candidates'] to vocab (previously: inline )]\n",
            "Dictionary: loading dictionary from /tmp/babi_memnn.dict\n",
            "[ num words =  26 ]\n",
            "[Memnn: full interactive mode on.]\n",
            " [ Setting fixed_candidates path to: /tmp/babi_memnn.cands-babi:task10k:1.cands ]\n",
            "Total parameters: 46,080 (46,080 trainable)\n",
            "Loading existing model parameters from /tmp/babi_memnn\n",
            "[ Loading fixed candidate set from /tmp/babi_memnn.cands-babi:task10k:1.cands ]\n",
            "[ Loading fixed candidate set vectors from /tmp/babi_memnn.babi_memnn.cands-babi:task10k:1.vecs ]\n",
            "[ Loading fixed candidate set encodings from /tmp/babi_memnn.babi_memnn.cands-babi:task10k:1.encs ]\n",
            "[ Loaded fixed candidate set (n = 57) from vocabulary ]\n",
            "[ Encoding fixed candidates set from (1 batch(es) of up to 256) ]\n",
            "\r  0% 0/1 [00:00<?, ?it/s]\r100% 1/1 [00:00<00:00, 1388.84it/s]\n",
            "[ optional arguments: ] \n",
            "[  display_examples: False ]\n",
            "[  display_ignore_fields: label_candidates,text_candidates ]\n",
            "[  display_prettify: False ]\n",
            "[  interactive_task: True ]\n",
            "[ Main ParlAI Arguments: ] \n",
            "[  batchsize: 1 ]\n",
            "[  datapath: /content/ParlAI/data ]\n",
            "[  datatype: train ]\n",
            "[  download_path: /content/ParlAI/downloads ]\n",
            "[  dynamic_batching: None ]\n",
            "[  hide_labels: False ]\n",
            "[  image_mode: raw ]\n",
            "[  init_opt: None ]\n",
            "[  multitask_weights: [1] ]\n",
            "[  numthreads: 4 ]\n",
            "[  show_advanced_args: False ]\n",
            "[  task: babi:task10k:1 ]\n",
            "[ ParlAI Model Arguments: ] \n",
            "[  dict_class: parlai.core.dict:DictionaryAgent ]\n",
            "[  init_model: None ]\n",
            "[  model: memnn ]\n",
            "[  model_file: /tmp/babi_memnn ]\n",
            "[ Local Human Arguments: ] \n",
            "[  local_human_candidates_file: None ]\n",
            "[  single_turn: False ]\n",
            "[ ParlAI Image Preprocessing Arguments: ] \n",
            "[  image_cropsize: 224 ]\n",
            "[  image_size: 256 ]\n",
            "[ MemNN Arguments: ] \n",
            "[  embedding_size: 128 ]\n",
            "[  hops: 3 ]\n",
            "[  memsize: 32 ]\n",
            "[  position_encoding: False ]\n",
            "[  time_features: True ]\n",
            "[ TorchAgent Arguments: ] \n",
            "[  add_p1_after_newln: True ]\n",
            "[  delimiter: \n",
            " ]\n",
            "[  embedding_projection: random ]\n",
            "[  embedding_type: random ]\n",
            "[  force_fp16_tokens: False ]\n",
            "[  fp16: False ]\n",
            "[  fp16_impl: apex ]\n",
            "[  gpu: -1 ]\n",
            "[  history_add_global_end_token: None ]\n",
            "[  history_size: -1 ]\n",
            "[  interactive_mode: True ]\n",
            "[  label_truncate: None ]\n",
            "[  no_cuda: True ]\n",
            "[  person_tokens: False ]\n",
            "[  rank_candidates: True ]\n",
            "[  split_lines: True ]\n",
            "[  text_truncate: None ]\n",
            "[  truncate: -1 ]\n",
            "[  use_reply: label ]\n",
            "[ Optimizer Arguments: ] \n",
            "[  adafactor_eps: [1e-30, 0.001] ]\n",
            "[  adam_eps: 1e-08 ]\n",
            "[  betas: [0.9, 0.999] ]\n",
            "[  gradient_clip: 0.1 ]\n",
            "[  learningrate: 1 ]\n",
            "[  momentum: 0 ]\n",
            "[  nesterov: True ]\n",
            "[  nus: [0.7] ]\n",
            "[  optimizer: sgd ]\n",
            "[  weight_decay: None ]\n",
            "[ Learning Rate Scheduler: ] \n",
            "[  invsqrt_lr_decay_gamma: -1 ]\n",
            "[  lr_scheduler: reduceonplateau ]\n",
            "[  lr_scheduler_decay: 0.5 ]\n",
            "[  lr_scheduler_patience: 3 ]\n",
            "[  max_lr_steps: -1 ]\n",
            "[  update_freq: 1 ]\n",
            "[  warmup_rate: 0.0001 ]\n",
            "[  warmup_updates: -1 ]\n",
            "[ TorchRankerAgent: ] \n",
            "[  candidates: inline ]\n",
            "[  cap_num_predictions: 100 ]\n",
            "[  encode_candidate_vecs: True ]\n",
            "[  encode_candidate_vecs_batchsize: 256 ]\n",
            "[  eval_candidates: vocab ]\n",
            "[  fixed_candidate_vecs: reuse ]\n",
            "[  fixed_candidates_path: None ]\n",
            "[  ignore_bad_candidates: False ]\n",
            "[  inference: max ]\n",
            "[  init_model: None ]\n",
            "[  interactive_candidates: fixed ]\n",
            "[  rank_top_k: -1 ]\n",
            "[  repeat_blocking_heuristic: True ]\n",
            "[  return_cand_scores: False ]\n",
            "[  topk: 5 ]\n",
            "[  train_predict: False ]\n",
            "[ Dictionary Arguments: ] \n",
            "[  bpe_debug: False ]\n",
            "[  dict_endtoken: __end__ ]\n",
            "[  dict_file: /tmp/babi_memnn.dict ]\n",
            "[  dict_initpath: None ]\n",
            "[  dict_language: english ]\n",
            "[  dict_lower: False ]\n",
            "[  dict_max_ngram_size: -1 ]\n",
            "[  dict_maxtokens: -1 ]\n",
            "[  dict_minfreq: 0 ]\n",
            "[  dict_nulltoken: __null__ ]\n",
            "[  dict_starttoken: __start__ ]\n",
            "[  dict_textfields: text,labels ]\n",
            "[  dict_tokenizer: re ]\n",
            "[  dict_unktoken: __unk__ ]\n",
            "[ BPEHelper Arguments: ] \n",
            "[  bpe_add_prefix_space: None ]\n",
            "[  bpe_merge: None ]\n",
            "[  bpe_vocab: None ]\n",
            "\u001b[1;31mEnter [DONE] if you want to end the episode, [EXIT] to quit.\u001b[0;0m\n",
            "[creating task(s): interactive]\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m John went to the hallway.\\n Where is John?\n",
            "/content/ParlAI/parlai/core/torch_ranker_agent.py:759: UserWarning: [ Executing eval mode with a common set of fixed candidates (n = 6). ]\n",
            "  \"(n = {}). ]\".format(mode, len(self.fixed_candidates))\n",
            "\u001b[0;34m[Memnn]:\u001b[0;0m \u001b[1mhallway\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m Traceback (most recent call last):\n",
            "  File \"/content/ParlAI/parlai/tasks/interactive/worlds.py\", line 64, in parley\n",
            "    act = deepcopy(agents[0].act())\n",
            "  File \"/content/ParlAI/parlai/agents/local_human/local_human.py\", line 67, in act\n",
            "    reply_text = input(colorize(\"Enter Your Message:\", 'text') + ' ')\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ParlAI/examples/interactive.py\", line 16, in <module>\n",
            "    Interactive.main()\n",
            "  File \"/content/ParlAI/parlai/scripts/script.py\", line 79, in main\n",
            "    return cls._run_args(None)\n",
            "  File \"/content/ParlAI/parlai/scripts/script.py\", line 66, in _run_args\n",
            "    script.run()\n",
            "  File \"/content/ParlAI/parlai/scripts/interactive.py\", line 92, in run\n",
            "    return interactive(self.opt, print_parser=self.parser)\n",
            "  File \"/content/ParlAI/parlai/scripts/interactive.py\", line 80, in interactive\n",
            "    world.parley()\n",
            "  File \"/content/ParlAI/parlai/tasks/interactive/worlds.py\", line 64, in parley\n",
            "    act = deepcopy(agents[0].act())\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfkqXDtOsHDY",
        "colab_type": "text"
      },
      "source": [
        "## Train a Transformer on Twitter\n",
        "Now let’s try training a Transformer (Vaswani, et al 2017) ranker model. Make sure to complete this section on a GPU with PyTorch installed.\n",
        "\n",
        "We’ll be training on the Twitter task, which is a dataset of tweets and replies. There’s more information on tasks in these docs, including a full list of tasks and instructions on specifying arguments for training and evaluation (like the -t <task> argument used here).\n",
        "\n",
        "Let’s begin again by printing the first few examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wxe3a5lFrZyf",
        "colab_type": "code",
        "outputId": "fe2d6ef5-b7e9-4537-ba47-1f6476074fa0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        }
      },
      "source": [
        "!python /content/ParlAI/examples/display_data.py -t twitter"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[creating task(s): twitter]\n",
            "[building data: /content/ParlAI/data/Twitter]\n",
            "[ downloading: https://github.com/Marsan-Ma/chat_corpus/raw/master/twitter_en_big.txt.gz.partaa to /content/ParlAI/data/Twitter/twitter_en_big.txt.gz.partaa ]\n",
            "Downloading twitter_en_big.txt.gz.partaa: 100% 83.9M/83.9M [00:01<00:00, 50.8MB/s]\n",
            "[ Checksum Successful ]\n",
            "[ downloading: https://github.com/Marsan-Ma/chat_corpus/raw/master/twitter_en_big.txt.gz.partab to /content/ParlAI/data/Twitter/twitter_en_big.txt.gz.partab ]\n",
            "Downloading twitter_en_big.txt.gz.partab: 100% 65.6M/65.6M [00:01<00:00, 36.7MB/s]\n",
            "[ Checksum Successful ]\n",
            "tcmalloc: large alloc 1498759168 bytes == 0x4de78000 @  0x7f1c1f0ce1e7 0x54485f 0x52dc9d 0x52ed2f 0x53e34a 0x5461a6 0x599f41 0x5668da 0x5a4be1 0x4b26bd 0x5a9cbc 0x50a5c3 0x50bfb4 0x509758 0x50a48d 0x50bfb4 0x509758 0x50a48d 0x50bfb4 0x507d64 0x5090b7 0x594931 0x549e5f 0x5513d1 0x5a9cbc 0x50a5c3 0x50bfb4 0x509758 0x50a48d 0x50bfb4 0x509758\n",
            "[loading parlAI text data:/content/ParlAI/data/Twitter/train.txt]\n",
            "\u001b[1;31m- - - NEW EPISODE: twitter - - -\u001b[0;0m\n",
            "\u001b[0mpsych is being taken off of netflix tomorrow and i have 8 episodes left and i work tonight kill me\u001b[0;0m\n",
            "   \u001b[1;94mbefore you go to work open each episode up in its own tab\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: twitter - - -\u001b[0;0m\n",
            "\u001b[0mcar door was clearly not open if you look at the video . you can see blood on the driver seat window\u001b[0;0m\n",
            "   \u001b[1;94mwould you have sat and waited to see if he had a gun or would you have saved your own life\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: twitter - - -\u001b[0;0m\n",
            "\u001b[0mi read the book also ! don't worry i'll be a good critic babe !\u001b[0;0m\n",
            "   \u001b[1;94maww thanks chalupa i know i can trust your taste @OK_hand@\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: twitter - - -\u001b[0;0m\n",
            "\u001b[0mno were at the nats game like true patriots\u001b[0;0m\n",
            "   \u001b[1;94mthe nats used to be canadian . try again .\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: twitter - - -\u001b[0;0m\n",
            "\u001b[0mmy twitter mentions are flying by like a 60 fps movie ever since i busted hillary for the teleprompter . someone is scared .\u001b[0;0m\n",
            "   \u001b[1;94m, please , please ! the confirm that you will honor this promise :\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: twitter - - -\u001b[0;0m\n",
            "\u001b[0mhappy days . best of luck\u001b[0;0m\n",
            "   \u001b[1;94mthank you ! !\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: twitter - - -\u001b[0;0m\n",
            "\u001b[0mburton is a fave of mine , even his average films are better than most directors .\u001b[0;0m\n",
            "   \u001b[1;94mkeeping my fingers crossed that he still has another ed wood in him before he retires .\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: twitter - - -\u001b[0;0m\n",
            "\u001b[0m\" i'm not running to be president of the world . i'm running to be president of the united states of america ! \" -\u001b[0;0m\n",
            "   \u001b[1;94mbut you already gave jerusalem to israel , and you think n korea shuld have nukes . sounds like world to me .\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: twitter - - -\u001b[0;0m\n",
            "\u001b[0mi saw someone say that we should use glass straws . .\u001b[0;0m\n",
            "   \u001b[1;94mglass or paper straws - preferably no 'straw' waste . ban !\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: twitter - - -\u001b[0;0m\n",
            "\u001b[0mnext friday\u001b[0;0m\n",
            "   \u001b[1;94mthats right the secret is out ! has now ! classic sitcoms all free2watch ! . . .\u001b[0;0m\n",
            "[ loaded 2580433 episodes with a total of 2580433 examples ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_aN1_QqsWtG",
        "colab_type": "text"
      },
      "source": [
        "Now, we’ll train the model. This will take a while to reach convergence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nHujRgjsVKd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python /content/ParlAI/examples/train_model.py -t twitter -mf /tmp/tr_twitter -m transformer/ranker -bs 10 -vtim 3600 -cands batch -ecands batch --data-parallel True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "El6dKAjnljnU",
        "colab_type": "text"
      },
      "source": [
        "This train model script evaluates the model on the valid and test sets at the end of training, but if we wanted to evaluate a saved model - perhaps to compare the results of our newly trained Transformer against a pretrained convai2 seq2seq baseline from our Model Zoo, we could do the following:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kab846d_sdd0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python ParlAI/examples/eval_model.py -t twitter -m legacy:seq2seq:0 -mf models:convai2/seq2seq/convai2_self_seq2seq_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMkI6_bTlqtC",
        "colab_type": "text"
      },
      "source": [
        "Finally, let’s print some of our transformer’s predictions with the same display_model script from above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KST1uEBkls0v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python ParlAI/examples/display_model.py -t twitter -mf /tmp/tr_twitter -ecands batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGdhKUOwlu3a",
        "colab_type": "text"
      },
      "source": [
        "## Add a simple model\n",
        "Let’s put together a super simple model which will print the parsed version of what is said to it.\n",
        "\n",
        "First let’s set it up."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTH1ATcsl2Mx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir ParlAI/parlai/agents/parrot\n",
        "!touch ParlAI/parlai/agents/parrot/parrot.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmgyeQrhmDgK",
        "colab_type": "text"
      },
      "source": [
        "We’ll inherit the TorchAgent parsing code so we don’t have to write it ourselves. Open parrot.py and copy the following:\n",
        "\n",
        "```python\n",
        "from parlai.core.torch_agent import TorchAgent, Output\n",
        "\n",
        "\n",
        "class ParrotAgent(TorchAgent):\n",
        "    def train_step(self, batch):\n",
        "        pass\n",
        "\n",
        "    def eval_step(self, batch):\n",
        "        # for each row in batch, convert tensor to back to text strings\n",
        "        return Output([self.dict.vec2txt(row) for row in batch.text_vec])\n",
        "\n",
        "    def build_model(self, batch):\n",
        "        # Our agent doesn't have a real model, so we will return a placeholder\n",
        "        # here.\n",
        "        return None\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDLYVYWjmC8j",
        "colab_type": "code",
        "outputId": "a17e49d0-71f6-4294-e4ff-a05c9e23df53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python ParlAI/examples/display_model.py -t babi:task10k:1 -m parrot"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ optional arguments: ] \n",
            "[  display_ignore_fields:  ]\n",
            "[  num_examples: 10 ]\n",
            "[  verbose: False ]\n",
            "[ Main ParlAI Arguments: ] \n",
            "[  batchsize: 1 ]\n",
            "[  datapath: /content/ParlAI/data ]\n",
            "[  datatype: valid ]\n",
            "[  download_path: /content/ParlAI/downloads ]\n",
            "[  dynamic_batching: None ]\n",
            "[  hide_labels: False ]\n",
            "[  image_mode: raw ]\n",
            "[  init_opt: None ]\n",
            "[  multitask_weights: [1] ]\n",
            "[  numthreads: 1 ]\n",
            "[  show_advanced_args: False ]\n",
            "[  task: babi:task10k:1 ]\n",
            "[ ParlAI Model Arguments: ] \n",
            "[  dict_class: parlai.core.dict:DictionaryAgent ]\n",
            "[  init_model: None ]\n",
            "[  model: parrot ]\n",
            "[  model_file: None ]\n",
            "[ ParlAI Image Preprocessing Arguments: ] \n",
            "[  image_cropsize: 224 ]\n",
            "[  image_size: 256 ]\n",
            "[ TorchAgent Arguments: ] \n",
            "[  add_p1_after_newln: False ]\n",
            "[  delimiter: \n",
            " ]\n",
            "[  embedding_projection: random ]\n",
            "[  embedding_type: random ]\n",
            "[  force_fp16_tokens: False ]\n",
            "[  fp16: False ]\n",
            "[  fp16_impl: apex ]\n",
            "[  gpu: -1 ]\n",
            "[  history_add_global_end_token: None ]\n",
            "[  history_size: -1 ]\n",
            "[  interactive_mode: False ]\n",
            "[  label_truncate: None ]\n",
            "[  no_cuda: False ]\n",
            "[  person_tokens: False ]\n",
            "[  rank_candidates: False ]\n",
            "[  split_lines: False ]\n",
            "[  text_truncate: None ]\n",
            "[  truncate: -1 ]\n",
            "[  use_reply: label ]\n",
            "[ Optimizer Arguments: ] \n",
            "[  adafactor_eps: (1e-30, 0.001) ]\n",
            "[  adam_eps: 1e-08 ]\n",
            "[  betas: (0.9, 0.999) ]\n",
            "[  gradient_clip: 0.1 ]\n",
            "[  learningrate: 1 ]\n",
            "[  momentum: 0 ]\n",
            "[  nesterov: True ]\n",
            "[  nus: (0.7,) ]\n",
            "[  optimizer: sgd ]\n",
            "[  weight_decay: None ]\n",
            "[ Dictionary Arguments: ] \n",
            "[  bpe_debug: False ]\n",
            "[  dict_endtoken: __end__ ]\n",
            "[  dict_file: None ]\n",
            "[  dict_initpath: None ]\n",
            "[  dict_language: english ]\n",
            "[  dict_lower: False ]\n",
            "[  dict_max_ngram_size: -1 ]\n",
            "[  dict_maxtokens: -1 ]\n",
            "[  dict_minfreq: 0 ]\n",
            "[  dict_nulltoken: __null__ ]\n",
            "[  dict_starttoken: __start__ ]\n",
            "[  dict_textfields: text,labels ]\n",
            "[  dict_tokenizer: re ]\n",
            "[  dict_unktoken: __unk__ ]\n",
            "[ BPEHelper Arguments: ] \n",
            "[  bpe_add_prefix_space: None ]\n",
            "[  bpe_merge: None ]\n",
            "[  bpe_vocab: None ]\n",
            "[ Learning Rate Scheduler: ] \n",
            "[  invsqrt_lr_decay_gamma: -1 ]\n",
            "[  lr_scheduler: reduceonplateau ]\n",
            "[  lr_scheduler_decay: 0.5 ]\n",
            "[  lr_scheduler_patience: 3 ]\n",
            "[  max_lr_steps: -1 ]\n",
            "[  update_freq: 1 ]\n",
            "[  warmup_rate: 0.0001 ]\n",
            "[  warmup_updates: -1 ]\n",
            "[ Current ParlAI commit: 08a2f5e5ad8ca67b831d5d55f8538361ff20b7cf ]\n",
            "[ Using CUDA ]\n",
            "[creating task(s): babi:task10k:1]\n",
            "[building data: /content/ParlAI/data/bAbI]\n",
            "[ downloading: http://parl.ai/downloads/babi/babi.tar.gz to /content/ParlAI/data/bAbI/babi.tar.gz ]\n",
            "Downloading babi.tar.gz: 100% 19.2M/19.2M [00:03<00:00, 5.19MB/s]\n",
            "[ Checksum Successful ]\n",
            "unpacking babi.tar.gz\n",
            "[loading fbdialog data:/content/ParlAI/data/bAbI/tasks_1-20_v1-2/en-valid-10k-nosf/qa1_valid.txt]\n",
            "\u001b[1;31m- - - NEW EPISODE: babi:task10k:1- - -\u001b[0;0m\n",
            "\u001b[0mSandra travelled to the office.\n",
            "Sandra went to the bathroom.\n",
            "Where is Sandra?\u001b[0;0m\n",
            "\u001b[1;94m    labels: bathroom\u001b[0;0m\n",
            "\u001b[0;95m     model: __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__\u001b[0;0m\n",
            "\u001b[0mMary went to the bedroom.\n",
            "Daniel moved to the hallway.\n",
            "Where is Sandra?\u001b[0;0m\n",
            "\u001b[1;94m    labels: bathroom\u001b[0;0m\n",
            "\u001b[0;95m     model: __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__\u001b[0;0m\n",
            "\u001b[0mJohn went to the garden.\n",
            "John travelled to the office.\n",
            "Where is Sandra?\u001b[0;0m\n",
            "\u001b[1;94m    labels: bathroom\u001b[0;0m\n",
            "\u001b[0;95m     model: __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__\u001b[0;0m\n",
            "\u001b[0mDaniel journeyed to the bedroom.\n",
            "Daniel travelled to the hallway.\n",
            "Where is John?\u001b[0;0m\n",
            "\u001b[1;94m    labels: office\u001b[0;0m\n",
            "\u001b[0;95m     model: __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__\u001b[0;0m\n",
            "\u001b[0mJohn went to the bedroom.\n",
            "John travelled to the office.\n",
            "Where is Daniel?\u001b[0;0m\n",
            "\u001b[1;94m    labels: hallway\u001b[0;0m\n",
            "\u001b[0;95m     model: __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: babi:task10k:1- - -\u001b[0;0m\n",
            "\u001b[0mSandra went back to the bathroom.\n",
            "Mary moved to the garden.\n",
            "Where is Mary?\u001b[0;0m\n",
            "\u001b[1;94m    labels: garden\u001b[0;0m\n",
            "\u001b[0;95m     model: __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__\u001b[0;0m\n",
            "\u001b[0mMary went back to the hallway.\n",
            "Sandra went to the office.\n",
            "Where is Sandra?\u001b[0;0m\n",
            "\u001b[1;94m    labels: office\u001b[0;0m\n",
            "\u001b[0;95m     model: __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__\u001b[0;0m\n",
            "\u001b[0mJohn went back to the hallway.\n",
            "John travelled to the office.\n",
            "Where is Sandra?\u001b[0;0m\n",
            "\u001b[1;94m    labels: office\u001b[0;0m\n",
            "\u001b[0;95m     model: __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__\u001b[0;0m\n",
            "\u001b[0mSandra journeyed to the hallway.\n",
            "Daniel moved to the office.\n",
            "Where is John?\u001b[0;0m\n",
            "\u001b[1;94m    labels: office\u001b[0;0m\n",
            "\u001b[0;95m     model: __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__\u001b[0;0m\n",
            "\u001b[0mMary went to the office.\n",
            "Sandra went to the office.\n",
            "Where is John?\u001b[0;0m\n",
            "\u001b[1;94m    labels: office\u001b[0;0m\n",
            "\u001b[0;95m     model: __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__ __unk__\u001b[0;0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0XMjjJNmemg",
        "colab_type": "text"
      },
      "source": [
        "You’ll notice the model is always outputting the “unknown” token. This token is automatically selected because the dictionary doesn’t recognize any tokens, because we haven’t built a dictionary yet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obzipmL3mSvr",
        "colab_type": "code",
        "outputId": "80bf6ff3-1c35-43f4-9f4a-89a622e124ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        }
      },
      "source": [
        "!python ParlAI/examples/build_dict.py -t babi:task10k:1 -df /tmp/parrot.dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ Main ParlAI Arguments: ] \n",
            "[  batchsize: 1 ]\n",
            "[  datapath: /content/ParlAI/data ]\n",
            "[  datatype: train ]\n",
            "[  download_path: /content/ParlAI/downloads ]\n",
            "[  dynamic_batching: None ]\n",
            "[  hide_labels: False ]\n",
            "[  image_mode: raw ]\n",
            "[  init_opt: None ]\n",
            "[  multitask_weights: [1] ]\n",
            "[  numthreads: 1 ]\n",
            "[  show_advanced_args: False ]\n",
            "[  task: babi:task10k:1 ]\n",
            "[ ParlAI Model Arguments: ] \n",
            "[  dict_class: None ]\n",
            "[  init_model: None ]\n",
            "[  model: None ]\n",
            "[  model_file: None ]\n",
            "[ Dictionary Loop Arguments: ] \n",
            "[  dict_include_test: False ]\n",
            "[  dict_include_valid: False ]\n",
            "[  dict_maxexs: -1 ]\n",
            "[  log_every_n_secs: 10 ]\n",
            "[ Dictionary Arguments: ] \n",
            "[  bpe_debug: False ]\n",
            "[  dict_endtoken: __end__ ]\n",
            "[  dict_file: /tmp/parrot.dict ]\n",
            "[  dict_initpath: None ]\n",
            "[  dict_language: english ]\n",
            "[  dict_lower: False ]\n",
            "[  dict_max_ngram_size: -1 ]\n",
            "[  dict_maxtokens: -1 ]\n",
            "[  dict_minfreq: 0 ]\n",
            "[  dict_nulltoken: __null__ ]\n",
            "[  dict_starttoken: __start__ ]\n",
            "[  dict_textfields: text,labels ]\n",
            "[  dict_tokenizer: re ]\n",
            "[  dict_unktoken: __unk__ ]\n",
            "[ BPEHelper Arguments: ] \n",
            "[  bpe_add_prefix_space: None ]\n",
            "[  bpe_merge: None ]\n",
            "[  bpe_vocab: None ]\n",
            "[ ParlAI Image Preprocessing Arguments: ] \n",
            "[  image_cropsize: 224 ]\n",
            "[  image_size: 256 ]\n",
            "[ Current ParlAI commit: 08a2f5e5ad8ca67b831d5d55f8538361ff20b7cf ]\n",
            "[creating task(s): babi:task10k:1]\n",
            "[loading fbdialog data:/content/ParlAI/data/bAbI/tasks_1-20_v1-2/en-valid-10k-nosf/qa1_train.txt]\n",
            "Building dictionary:   0% 0.00/9.00k [00:00<?, ?ex/s][loading fbdialog data:/content/ParlAI/data/bAbI/tasks_1-20_v1-2/en-valid-10k-nosf/qa1_train.txt]\n",
            "Building dictionary: 100% 9.00k/9.00k [00:00<00:00, 19.2kex/s]\n",
            "Dictionary: saving dictionary to /tmp/parrot.dict\n",
            "[ dictionary built with 26 tokens in 0s ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJrpNNZDDf-r",
        "colab_type": "text"
      },
      "source": [
        "Now let’s try our Parrot agent again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyOiEgclmjuc",
        "colab_type": "code",
        "outputId": "9abaaf37-ee65-4dd7-91ea-e718d13c23b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python ParlAI/examples/display_model.py -t babi:task10k:1 -m parrot -df /tmp/parrot.dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ optional arguments: ] \n",
            "[  display_ignore_fields:  ]\n",
            "[  num_examples: 10 ]\n",
            "[  verbose: False ]\n",
            "[ Main ParlAI Arguments: ] \n",
            "[  batchsize: 1 ]\n",
            "[  datapath: /content/ParlAI/data ]\n",
            "[  datatype: valid ]\n",
            "[  download_path: /content/ParlAI/downloads ]\n",
            "[  dynamic_batching: None ]\n",
            "[  hide_labels: False ]\n",
            "[  image_mode: raw ]\n",
            "[  init_opt: None ]\n",
            "[  multitask_weights: [1] ]\n",
            "[  numthreads: 1 ]\n",
            "[  show_advanced_args: False ]\n",
            "[  task: babi:task10k:1 ]\n",
            "[ ParlAI Model Arguments: ] \n",
            "[  dict_class: parlai.core.dict:DictionaryAgent ]\n",
            "[  init_model: None ]\n",
            "[  model: parrot ]\n",
            "[  model_file: None ]\n",
            "[ ParlAI Image Preprocessing Arguments: ] \n",
            "[  image_cropsize: 224 ]\n",
            "[  image_size: 256 ]\n",
            "[ TorchAgent Arguments: ] \n",
            "[  add_p1_after_newln: False ]\n",
            "[  delimiter: \n",
            " ]\n",
            "[  embedding_projection: random ]\n",
            "[  embedding_type: random ]\n",
            "[  force_fp16_tokens: False ]\n",
            "[  fp16: False ]\n",
            "[  fp16_impl: apex ]\n",
            "[  gpu: -1 ]\n",
            "[  history_add_global_end_token: None ]\n",
            "[  history_size: -1 ]\n",
            "[  interactive_mode: False ]\n",
            "[  label_truncate: None ]\n",
            "[  no_cuda: False ]\n",
            "[  person_tokens: False ]\n",
            "[  rank_candidates: False ]\n",
            "[  split_lines: False ]\n",
            "[  text_truncate: None ]\n",
            "[  truncate: -1 ]\n",
            "[  use_reply: label ]\n",
            "[ Optimizer Arguments: ] \n",
            "[  adafactor_eps: (1e-30, 0.001) ]\n",
            "[  adam_eps: 1e-08 ]\n",
            "[  betas: (0.9, 0.999) ]\n",
            "[  gradient_clip: 0.1 ]\n",
            "[  learningrate: 1 ]\n",
            "[  momentum: 0 ]\n",
            "[  nesterov: True ]\n",
            "[  nus: (0.7,) ]\n",
            "[  optimizer: sgd ]\n",
            "[  weight_decay: None ]\n",
            "[ Dictionary Arguments: ] \n",
            "[  bpe_debug: False ]\n",
            "[  dict_endtoken: __end__ ]\n",
            "[  dict_file: /tmp/parrot.dict ]\n",
            "[  dict_initpath: None ]\n",
            "[  dict_language: english ]\n",
            "[  dict_lower: False ]\n",
            "[  dict_max_ngram_size: -1 ]\n",
            "[  dict_maxtokens: -1 ]\n",
            "[  dict_minfreq: 0 ]\n",
            "[  dict_nulltoken: __null__ ]\n",
            "[  dict_starttoken: __start__ ]\n",
            "[  dict_textfields: text,labels ]\n",
            "[  dict_tokenizer: re ]\n",
            "[  dict_unktoken: __unk__ ]\n",
            "[ BPEHelper Arguments: ] \n",
            "[  bpe_add_prefix_space: None ]\n",
            "[  bpe_merge: None ]\n",
            "[  bpe_vocab: None ]\n",
            "[ Learning Rate Scheduler: ] \n",
            "[  invsqrt_lr_decay_gamma: -1 ]\n",
            "[  lr_scheduler: reduceonplateau ]\n",
            "[  lr_scheduler_decay: 0.5 ]\n",
            "[  lr_scheduler_patience: 3 ]\n",
            "[  max_lr_steps: -1 ]\n",
            "[  update_freq: 1 ]\n",
            "[  warmup_rate: 0.0001 ]\n",
            "[  warmup_updates: -1 ]\n",
            "[ Current ParlAI commit: 08a2f5e5ad8ca67b831d5d55f8538361ff20b7cf ]\n",
            "[ Using CUDA ]\n",
            "Dictionary: loading dictionary from /tmp/parrot.dict\n",
            "[ num words =  26 ]\n",
            "[creating task(s): babi:task10k:1]\n",
            "[loading fbdialog data:/content/ParlAI/data/bAbI/tasks_1-20_v1-2/en-valid-10k-nosf/qa1_valid.txt]\n",
            "\u001b[1;31m- - - NEW EPISODE: babi:task10k:1- - -\u001b[0;0m\n",
            "\u001b[0mSandra travelled to the office.\n",
            "Sandra went to the bathroom.\n",
            "Where is Sandra?\u001b[0;0m\n",
            "\u001b[1;94m    labels: bathroom\u001b[0;0m\n",
            "\u001b[0;95m     model: Sandra travelled to the office . \n",
            " Sandra went to the bathroom . \n",
            " Where is Sandra ?\u001b[0;0m\n",
            "\u001b[0mMary went to the bedroom.\n",
            "Daniel moved to the hallway.\n",
            "Where is Sandra?\u001b[0;0m\n",
            "\u001b[1;94m    labels: bathroom\u001b[0;0m\n",
            "\u001b[0;95m     model: Sandra travelled to the office . \n",
            " Sandra went to the bathroom . \n",
            " Where is Sandra ? \n",
            " bathroom \n",
            " Mary went to the bedroom . \n",
            " Daniel moved to the hallway . \n",
            " Where is Sandra ?\u001b[0;0m\n",
            "\u001b[0mJohn went to the garden.\n",
            "John travelled to the office.\n",
            "Where is Sandra?\u001b[0;0m\n",
            "\u001b[1;94m    labels: bathroom\u001b[0;0m\n",
            "\u001b[0;95m     model: Sandra travelled to the office . \n",
            " Sandra went to the bathroom . \n",
            " Where is Sandra ? \n",
            " bathroom \n",
            " Mary went to the bedroom . \n",
            " Daniel moved to the hallway . \n",
            " Where is Sandra ? \n",
            " bathroom \n",
            " John went to the garden . \n",
            " John travelled to the office . \n",
            " Where is Sandra ?\u001b[0;0m\n",
            "\u001b[0mDaniel journeyed to the bedroom.\n",
            "Daniel travelled to the hallway.\n",
            "Where is John?\u001b[0;0m\n",
            "\u001b[1;94m    labels: office\u001b[0;0m\n",
            "\u001b[0;95m     model: Sandra travelled to the office . \n",
            " Sandra went to the bathroom . \n",
            " Where is Sandra ? \n",
            " bathroom \n",
            " Mary went to the bedroom . \n",
            " Daniel moved to the hallway . \n",
            " Where is Sandra ? \n",
            " bathroom \n",
            " John went to the garden . \n",
            " John travelled to the office . \n",
            " Where is Sandra ? \n",
            " bathroom \n",
            " Daniel journeyed to the bedroom . \n",
            " Daniel travelled to the hallway . \n",
            " Where is John ?\u001b[0;0m\n",
            "\u001b[0mJohn went to the bedroom.\n",
            "John travelled to the office.\n",
            "Where is Daniel?\u001b[0;0m\n",
            "\u001b[1;94m    labels: hallway\u001b[0;0m\n",
            "\u001b[0;95m     model: Sandra travelled to the office . \n",
            " Sandra went to the bathroom . \n",
            " Where is Sandra ? \n",
            " bathroom \n",
            " Mary went to the bedroom . \n",
            " Daniel moved to the hallway . \n",
            " Where is Sandra ? \n",
            " bathroom \n",
            " John went to the garden . \n",
            " John travelled to the office . \n",
            " Where is Sandra ? \n",
            " bathroom \n",
            " Daniel journeyed to the bedroom . \n",
            " Daniel travelled to the hallway . \n",
            " Where is John ? \n",
            " office \n",
            " John went to the bedroom . \n",
            " John travelled to the office . \n",
            " Where is Daniel ?\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: babi:task10k:1- - -\u001b[0;0m\n",
            "\u001b[0mSandra went back to the bathroom.\n",
            "Mary moved to the garden.\n",
            "Where is Mary?\u001b[0;0m\n",
            "\u001b[1;94m    labels: garden\u001b[0;0m\n",
            "\u001b[0;95m     model: Sandra went back to the bathroom . \n",
            " Mary moved to the garden . \n",
            " Where is Mary ?\u001b[0;0m\n",
            "\u001b[0mMary went back to the hallway.\n",
            "Sandra went to the office.\n",
            "Where is Sandra?\u001b[0;0m\n",
            "\u001b[1;94m    labels: office\u001b[0;0m\n",
            "\u001b[0;95m     model: Sandra went back to the bathroom . \n",
            " Mary moved to the garden . \n",
            " Where is Mary ? \n",
            " garden \n",
            " Mary went back to the hallway . \n",
            " Sandra went to the office . \n",
            " Where is Sandra ?\u001b[0;0m\n",
            "\u001b[0mJohn went back to the hallway.\n",
            "John travelled to the office.\n",
            "Where is Sandra?\u001b[0;0m\n",
            "\u001b[1;94m    labels: office\u001b[0;0m\n",
            "\u001b[0;95m     model: Sandra went back to the bathroom . \n",
            " Mary moved to the garden . \n",
            " Where is Mary ? \n",
            " garden \n",
            " Mary went back to the hallway . \n",
            " Sandra went to the office . \n",
            " Where is Sandra ? \n",
            " office \n",
            " John went back to the hallway . \n",
            " John travelled to the office . \n",
            " Where is Sandra ?\u001b[0;0m\n",
            "\u001b[0mSandra journeyed to the hallway.\n",
            "Daniel moved to the office.\n",
            "Where is John?\u001b[0;0m\n",
            "\u001b[1;94m    labels: office\u001b[0;0m\n",
            "\u001b[0;95m     model: Sandra went back to the bathroom . \n",
            " Mary moved to the garden . \n",
            " Where is Mary ? \n",
            " garden \n",
            " Mary went back to the hallway . \n",
            " Sandra went to the office . \n",
            " Where is Sandra ? \n",
            " office \n",
            " John went back to the hallway . \n",
            " John travelled to the office . \n",
            " Where is Sandra ? \n",
            " office \n",
            " Sandra journeyed to the hallway . \n",
            " Daniel moved to the office . \n",
            " Where is John ?\u001b[0;0m\n",
            "\u001b[0mMary went to the office.\n",
            "Sandra went to the office.\n",
            "Where is John?\u001b[0;0m\n",
            "\u001b[1;94m    labels: office\u001b[0;0m\n",
            "\u001b[0;95m     model: Sandra went back to the bathroom . \n",
            " Mary moved to the garden . \n",
            " Where is Mary ? \n",
            " garden \n",
            " Mary went back to the hallway . \n",
            " Sandra went to the office . \n",
            " Where is Sandra ? \n",
            " office \n",
            " John went back to the hallway . \n",
            " John travelled to the office . \n",
            " Where is Sandra ? \n",
            " office \n",
            " Sandra journeyed to the hallway . \n",
            " Daniel moved to the office . \n",
            " Where is John ? \n",
            " office \n",
            " Mary went to the office . \n",
            " Sandra went to the office . \n",
            " Where is John ?\u001b[0;0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3qdmWgqDmRA",
        "colab_type": "text"
      },
      "source": [
        "This ParrotAgent implements `eval_step`, one of two abstract functions in `TorchAgent`. The other is `train_step`. You can easily and quickly build a model agent by creating a class which implements only these two functions with the most typical custom code for a model, and inheriting vectorization and batching from `TorchAgent`.\n",
        "\n",
        "As needed, you can also override any functions to change the default argument values or to override the behavior with your own."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuoQyogbD4nM",
        "colab_type": "text"
      },
      "source": [
        "# Intro to ParlAI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPKPfbBFEHG7",
        "colab_type": "text"
      },
      "source": [
        "## What is ParlAI?\n",
        "- a unified framework for sharing, training and testing dialog models\n",
        "\n",
        "- many popular datasets available all in one place, with the ability to multi-task over them\n",
        "\n",
        "- seamless integration of Amazon Mechanical Turk for data collection and human evaluation\n",
        "\n",
        "- integration with chat services like Facebook Messenger to connect agents with humans in a chat interface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQRhaayDEP7c",
        "colab_type": "text"
      },
      "source": [
        "## Core Concepts\n",
        "In ParlAI, we call an environment a world. In each world, there are agents. Examples of agents include models and datasets. Agents interact with each other by taking turns acting and observing acts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBjCwUptFmt9",
        "colab_type": "text"
      },
      "source": [
        "### Agents\n",
        "The most basic concept in ParlAI is an `Agent`. An agent can be a human, a simple bot which repeats back anything that it hears, your perfectly tuned neural network, a dataset being read out, or anything else that might send messages or interact with its environment.\n",
        "\n",
        "Agents have two primary methods they need to define:\n",
        "\n",
        "```python\n",
        "def observe(self, observation): # update internal state with observation\n",
        "def act(self): # produce action based on internal state\n",
        "```\n",
        "\n",
        "- `observe()` takes as input an observation `dict`, which is usually the result of an action taken by another agent, and updates this agent’s internal state accordingly.\n",
        "\n",
        "- `act()` produces an action from the agent. For a dataset agent, this might increment a counter for examples seen and return the next batch of examples. For a neural net agent, this could be a `train` step or `eval` step.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDR1Gzy6S2Kb",
        "colab_type": "text"
      },
      "source": [
        "### Messages\n",
        "Messages are what we call the objects both observed by an `agent` (observations) and returned by an agent’s `act` function (actions). These observations and actions are the primary way agents in ParlAI communicate with each other within their enviroment. The `Message` object is a subclass of a python `dict`, whose key function is to prevent users from editing fields in an action or observation unintentionally.\n",
        "\n",
        "Note: during validation and testing, the labels field is renamed `eval_labels` – this way, the model won’t accidentally train on the labels, but they are still available for calculating model-side loss. Models can check if they are training on a supervised task in the following manner:\n",
        "```python\n",
        "is_training = 'labels' in observation\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzHH8Y28S5s-",
        "colab_type": "text"
      },
      "source": [
        "### Teachers\n",
        "A `Teacher` is special type of agent. They implement the `act` and `observe` functions as all agents do, but they also keep track of metrics which they return via a report function, such as the number of questions they have posed or how many times those questions have been answered correctly.\n",
        "\n",
        "Datasets and tasks typically implement a subclass of `Teacher`, providing functions which download the dataset from its source if necessary, read the file into the right format, and return an example with each call to the teacher’s act function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSlLXXmKTMYy",
        "colab_type": "text"
      },
      "source": [
        "### Worlds\n",
        "Worlds define the environment in which agents interact with one another. Worlds must implement a `parley` method. Each call to `parley` conducts one turn of interactions typically containing one action per agent.\n",
        "\n",
        "A simple world included in ParlAI, which all of our currently included tasks use, is the `DialogPartnerWorld`. `DialogPartnerWorld` is initialized with one task teacher agent and one student agent. With each call to `parley`, one exchange is done between the agents, in the following manner:\n",
        "```python\n",
        "query = teacher.act()\n",
        "student.observe(query)\n",
        "reply = student.act()\n",
        "teacher.observe(reply)\n",
        "```\n",
        "Another simple world we include is `MultiAgentDialogWorld`, which is similar but generalizes this to cycle between any number of agents in a `round robin` fashion."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_rfC1h1T6cN",
        "colab_type": "text"
      },
      "source": [
        "## Using ParlAI\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHHwlByDUCKw",
        "colab_type": "text"
      },
      "source": [
        "### Concepts in Action: Simple Display Data Script\n",
        "Now that we understand the basics, let’s set up a simple script which displays any specified task. A complete version of this for utility is included at `parlai/scripts/display_data.py`, but we’ll do this from scratch to demonstrate the concepts we just introduced.\n",
        "\n",
        "We’ll create a new agent class and implement `observe()` and `act()` functions so that, in a world with a task teacher, it will observe the data outputted by the task teacher, save the data as its last observation, and then act by printing the label in its observation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erG9592yEFqm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from parlai.core.agents import Agent\n",
        "from parlai.core.params import ParlaiParser\n",
        "from parlai.core.worlds import create_task"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-CONfLdUCGW",
        "colab_type": "text"
      },
      "source": [
        "The Agent class will be the parent class for our own agent. The ParlaiParser provides a set of default command-line arguments and parsing, and create_task will automatically set up the appropriate world and teacher for any task available within ParlAI that we choose.\n",
        "\n",
        "We define our agent (which we name RepeatLabelAgent):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__B7Vx4SUUii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RepeatLabelAgent(Agent):\n",
        "\n",
        "    # initialize by setting id\n",
        "    def __init__(self, opt):\n",
        "        self.id = 'RepeatLabel'\n",
        "    \n",
        "    # store observation for later, return it unmodified\n",
        "    def observe(self, observation):\n",
        "        self.observation = observation\n",
        "        return observation\n",
        "    \n",
        "    # return label from before if available\n",
        "    def act(self):\n",
        "        reply = {'id': self.id}\n",
        "        if 'labels' in self.observation:\n",
        "            reply['text'] = ', '.join(self.observation['labels'])\n",
        "        else:\n",
        "            reply['text'] = \"I don't know.\"\n",
        "        return reply"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvDqubnAUVnP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parser = ParlaiParser()\n",
        "opt = parser.parse_args()\n",
        "\n",
        "agent = RepeatLabelAgent(opt)\n",
        "world = create_task(opt, agent)\n",
        "\n",
        "for _ in range(10):\n",
        "    world.parley()\n",
        "    print(world.display())\n",
        "    if world.epoch_done():\n",
        "        print('EPOCH DONE')\n",
        "        break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6Jr8gqJp3oS",
        "colab_type": "text"
      },
      "source": [
        "### Validation and Testing\n",
        "During validation and testing, the `labels` field is removed from the observation dict. This tells the agent not to use these labels for training–however, the labels are still available via the `eval_labels` field in case you need to compute model-side metrics such as perplexity.\n",
        "\n",
        "In these cases, our RepeatLabel agent no longer has anything to say. For datasets which provide a set of candidates to choose from (`label_candidates` in the observation dict), we can give our agent a chance of getting the answer correct by replying with one of those.\n",
        "\n",
        "Let’s modify our agent’s act function to select a random label candidate when the labels aren’t available:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuAFeRPGUohe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "def act(self):\n",
        "    reply = {'id': self.id}\n",
        "    if 'labels' in self.observation:\n",
        "        reply['text'] = ', '.join(self.observation['labels'])\n",
        "    elif 'label_candidates' in self.observation:\n",
        "        cands = self.observation['label_candidates']\n",
        "        reply['text'] = random.choice(list(cands))\n",
        "    else:\n",
        "        reply['text'] = \"I don't know.\"\n",
        "    return reply"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYWo7TQPqHr8",
        "colab_type": "text"
      },
      "source": [
        "### Tasks\n",
        "If you run this on the command line, you can **specify which task to show by setting ‘-t {task}’** in the following format:\n",
        "\n",
        "- `-t babi` sets up the `DefaultTeacher` in `parlai/core/tasks/babi/agents.py`.\n",
        "\n",
        "- `-t babi:task1k` sets up the `Task1kTeacher` in the `babi/agents.py` file, which allows you to specify specific settings for certain tasks. For bAbI, this refers to the setting where there are only 1000 unique training examples per task.\n",
        "\n",
        "- `-t babi:task1k:1` provides 1 as a parameter to Task1kTeacher, which is interpreted by the Task1kTeacher to mean “I want task 1” (as opposed to the 19 other bAbI tasks).\n",
        "\n",
        "- `-t babi,squad` sets up the DefaultTeacher for both babi and squad. Any number of tasks can be chained together with commas to load up each one of them.\n",
        "\n",
        "- `-t #qa` specifies the ‘qa’ category, loading up all tasks with that category in the `parlai/core/task_list.py` file.\n",
        "\n",
        "These flags are used across ParlAI. Here are some examples of using them for displaying data with the existing script display_data:\n",
        "\n",
        "```python\n",
        "#Display 10 random examples from task 1 of the \"1k training examples\" bAbI task:\n",
        "python examples/display_data.py -t babi:task1k:1\n",
        "\n",
        "#Displays 100 random examples from multi-tasking on the bAbI task and the SQuAD dataset at the same time:\n",
        "python examples/display_data.py -t babi:task1k:1,squad -n 100\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkwBSf9r5qpK",
        "colab_type": "text"
      },
      "source": [
        "### Datatype\n",
        "In the last section, we mentioned that labels are hidden at validation and test time. The `–datatype` (`-dt`) flag specifies `train`, `valid` or `test`. These modes can be set from the command line with `-dt valid` / `-dt test`. You can also set `-dt train:evalmode` if you want to look at the train data in the same way as the test data (with labels hidden)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csDhaRgl57GS",
        "colab_type": "text"
      },
      "source": [
        "Some examples\n",
        "\n",
        "```python\n",
        "# Train a seq2seq model on the \"10k training examples\" bAbI task 1 with batch size of 32 examples until accuracy reaches 95% on validation (requires pytorch):\n",
        "python examples/train_model.py -t babi:task10k:1 -m seq2seq -mf /tmp/model_s2s -bs 32 -vtim 30 -vcut 0.95\n",
        "\n",
        "# Trains an attentive LSTM model on the SQuAD dataset with a batch size of 32 examples (pytorch and regex):\n",
        "python examples/train_model.py -m drqa -t squad -bs 32 -mf /tmp/model_drqa\n",
        "\n",
        "# Tests an existing attentive LSTM model (DrQA reader) on the SQuAD dataset from our model zoo:\n",
        "python examples/eval_model.py -t squad -mf \"zoo:drqa/squad/model\"\n",
        "\n",
        "# Evaluate on the bAbI test set with a human agent (using the local keyboard as input):\n",
        "python examples/eval_model.py -m local_human -t babi:Task1k:1 -dt valid\n",
        "\n",
        "# Evaluate an IR baseline model on the validation set of the Movies Subreddit dataset:\n",
        "python examples/eval_model.py -m ir_baseline -t \"#moviedd-reddit\" -dt valid\n",
        "\n",
        "# Display the predictions of that same IR baseline model:\n",
        "python examples/display_model.py -m ir_baseline -t \"#moviedd-reddit\" -dt valid\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pML-a8cb_8TM",
        "colab_type": "text"
      },
      "source": [
        "### Training and Evaluating Existing Agents\n",
        "For now, we’ll look at the scripts we’ve provided for training and evaluation: train_model and eval_model. Here are some examples:\n",
        "\n",
        "```python\n",
        "# Train a seq2seq model on the \"10k training examples\" bAbI task 1 with batch size of 32 examples until accuracy reaches 95% on validation (requires pytorch):\n",
        "python examples/train_model.py -t babi:task10k:1 -m seq2seq -mf /tmp/model_s2s -bs 32 -vtim 30 -vcut 0.95\n",
        "\n",
        "# Trains an attentive LSTM model on the SQuAD dataset with a batch size of 32 examples (pytorch and regex):\n",
        "python examples/train_model.py -m drqa -t squad -bs 32 -mf /tmp/model_drqa\n",
        "\n",
        "# Tests an existing attentive LSTM model (DrQA reader) on the SQuAD dataset from our model zoo:\n",
        "python examples/eval_model.py -t squad -mf \"zoo:drqa/squad/model\"\n",
        "\n",
        "# Evaluate on the bAbI test set with a human agent (using the local keyboard as input):\n",
        "python examples/eval_model.py -m local_human -t babi:Task1k:1 -dt valid\n",
        "\n",
        "# Evaluate an IR baseline model on the validation set of the Movies Subreddit dataset:\n",
        "python examples/eval_model.py -m ir_baseline -t \"#moviedd-reddit\" -dt valid\n",
        "\n",
        "# Display the predictions of that same IR baseline model:\n",
        "python examples/display_model.py -m ir_baseline -t \"#moviedd-reddit\" -dt valid\n",
        "```\n",
        "\n",
        "The main flags are:\n",
        "\n",
        "1. `-m` (`-model`) which sets the agent type that will be trained. The agents available in parlAI are here. See this tutorial for making your own agents.\n",
        "\n",
        "2. `-mf` (`–modelfile`) points to the file name of where to save your model.\n",
        "\n",
        "3. `-t` (`–task`) as described before."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hyaw8RpFeNK2",
        "colab_type": "text"
      },
      "source": [
        "### Interacting with Models\n",
        "One can also talk to your models! Here are examples of talking to models already in the model zoo:\n",
        "```python\n",
        "# Interact with a Poly-Encoder model on ConvAI2\n",
        "python examples/interactive.py -mf zoo:pretrained_transformers/model_poly/model -t convai2\n",
        "\n",
        "# Interact with a Wizard Of Wikipedia (Full Dialogue Retrieval Model).\n",
        "python examples/interactive.py -m projects:wizard_of_wikipedia:interactive_retrieval -t wizard_of_wikipedia\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMdk1eUoqKlZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}