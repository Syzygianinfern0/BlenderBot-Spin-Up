{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3. BlenderBot.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTK56hsk4hLJ",
        "colab_type": "text"
      },
      "source": [
        "# Recipes for building an open-domain chatbot\n",
        "\n",
        "## Chatting with the models\n",
        "You may talk with our models. The 2.7B can be interacted with on a 16gb P100 GPU or better. The 9.4B parameter model requires at least two 32gb V100 GPUs to interact with.\n",
        "\n",
        "Safety We have studied improved safety from toxic language (Dinan et al., 2019b), but much work remains to be done. While we have made our models publicly available, and added a safety layer to the interaction, we have not mitigated all safety issues. We believe their release can help the community work together to understand further and fix these issues, and we recommend their use for that line of research.\n",
        "\n",
        "```python\n",
        "# 90M\n",
        "python parlai/scripts/safe_interactive.py -t blended_skill_talk -mf zoo:blender/blender_90M/model\n",
        "\n",
        "# 2.7B\n",
        "python parlai/scripts/safe_interactive.py -t blended_skill_talk -mf zoo:blender/blender_3B/model\n",
        "\n",
        "# 9.4B\n",
        "python parlai/scripts/safe_interactive.py -t blended_skill_talk -mf zoo:blender/blender_9B/model\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttchs7WjMtNZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/facebookresearch/ParlAI.git ;\\\n",
        "    cd ParlAI ;\\\n",
        "    python setup.py develop"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BslucOyZN4Wn",
        "colab_type": "code",
        "outputId": "1d175caa-1fce-4564-a0b1-89d7bccecd72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "!pip install 'git+https://github.com/rsennrich/subword-nmt.git#egg=subword-nmt'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting subword-nmt\n",
            "  Cloning https://github.com/rsennrich/subword-nmt.git to /tmp/pip-install-kam28vui/subword-nmt\n",
            "  Running command git clone -q https://github.com/rsennrich/subword-nmt.git /tmp/pip-install-kam28vui/subword-nmt\n",
            "Building wheels for collected packages: subword-nmt\n",
            "  Building wheel for subword-nmt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subword-nmt: filename=subword_nmt-0.3.7-cp36-none-any.whl size=128391 sha256=0bca92c256f99ae70ce2efacb6b5be1ec510a8e51dc926d5a5938ef8cc155fe5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-gtf1877r/wheels/05/2b/3a/73cd213b79c18512c76a9ea40329a6819fa9276e232679d834\n",
            "Successfully built subword-nmt\n",
            "Installing collected packages: subword-nmt\n",
            "Successfully installed subword-nmt-0.3.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTcT1Rl-M5m2",
        "colab_type": "code",
        "outputId": "0edde16d-3c34-4487-bc3d-3a6429dae485",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!cd ParlAI ;\\\n",
        "    python parlai/scripts/safe_interactive.py -t blended_skill_talk -mf zoo:blender/blender_90M/model"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "                                 /@&%###%&&@@#\n",
            "                      .,*/((((##@@@&%%#%%&&@@@&%%#/*.\n",
            "             #@@&&&%%%%##(((///*****//(((###%%%&&&@@@@@&&%#%%#.\n",
            "         .%&@@@@@&&&%%%####((((////((((####%%%&&&@@@@@&&%%#%%####,\n",
            "           ./,,#(//**,,.....,,,,***////((((########%%%%%%%%###(((\n",
            "              /*(//**,,,....,,,,***////((((########%%%%%%%%###(#%*\n",
            "               (*,...      ...,,,***//////((((((///////(/*...,/#@@@(\n",
            "               **,,..         ...,,,,,,,,,,........,,*///*...*(#@@@@&&*\n",
            "               ./,,..          ...,,,,,,,,,........,,*//*,...*#/,,,,,/%#\n",
            "                (*,..          ...,,,,,,,,,........,,*//*,..,/(      .,#(\n",
            "                **,..          ...,,,,,,,,,.........,*//*,..,((       .,(#\n",
            "                 /*,..          ....,,,,,,,.....  ..,***,,,,(#         ..#&\n",
            "                 **,..          ....,,,,,,,....   ..,***,,,*#.         .,%@\n",
            "                 ./,...       B l e n d e r B o t ...***,,,*#          .*%@\n",
            "                  /*,..          ...,,,,,,,....    .,**,,,,/#         ..(%/\n",
            "                  /*,,..         ...,,,,,,,...    ..,*,,,,,(.         ..#&\n",
            "                  ,/*,..         ...,,,,,,,...    ..,*,,,,*#         ..*%(\n",
            "                   /*,..         ...,,,,,.....    ..,*,*,,/(         ..#&\n",
            "                   /**,..        ...,,,,.....    ...,***,*(.       ,,(%.\n",
            "                    (/*,,..      ....,,.....     ...,****(&@@@&&&#,\n",
            "                     (/*,,...   .....,,......     ..,****#@,\n",
            "                     *(/*,,/....*(###%(,(%%##(*.  ./,,**(\n",
            "                      ,//**(,........,/((#.........*,**(\n",
            "                      .(#//*,,,,,,.*.,/((%/,,.....,,*/@\n",
            "                    ((######//****,/.,/(#%#***,***(&@@@@@(\n",
            "                   *&%%#####%%%%%%%#//(#%&%%&&@@@@@@@@@@@@*\n",
            "                   &&%%%###((((((####%%%%&&&&&@@@@@@@@@@&&@.\n",
            "                  *##%%%##(((((((####%%%%%&&&&@@@@@@@@@&#/*,\n",
            "                 .(##%#/,  .,*((##%%%&&&&%%%#####%&&@&&%#(/*.\n",
            "                 /(###(,   .,*/(##%%%&&&&%%%######%&&&&%#(/*,\n",
            "                */((((*.  ..,//((##%%%%%%%%#######%&&&&%%#(/*,\n",
            "               .//(((/,   .,*//((###%%%%%%########%%&&&%%#((/,.\n",
            "              .&####(((((((((######%%%%%%%%&&&&&&&@@@@@@@@@@@@@#\n",
            "               *&#.   .*/((((#######%%%%%%&&&&&&&@@@@@#/.   (&/\n",
            "[building data: /content/ParlAI/data/models/blender/blender_90M/BST0B.tgz]\n",
            "[ downloading: http://parl.ai/downloads/_models/blender/BST0B.tgz to /content/ParlAI/data/models/blender/blender_90M/BST0B.tgz ]\n",
            "Downloading BST0B.tgz: 100% 161M/161M [00:07<00:00, 22.0MB/s]\n",
            "unpacking BST0B.tgz\n",
            "[ warning: overriding opt['task'] to blended_skill_talk (previously: internal:blended_skill_talk,wizard_of_wikipedia,convai2,empathetic_dialogues )]\n",
            "[ warning: overriding opt['model_file'] to /content/ParlAI/data/models/blender/blender_90M/model (previously: /checkpoint/edinan/20200210/baseline_BST_retnref/lr=7.5e-06_attention-dropout=0.0_relu-dropout=0.0/model )]\n",
            "[ Using CUDA ]\n",
            "/content/ParlAI/parlai/utils/fp16.py:144: UserWarning: You set --fp16 true with --fp16-impl apex, but fp16 with apex is unavailable. To use apex fp16, please install APEX from https://github.com/NVIDIA/apex.\n",
            "  'You set --fp16 true with --fp16-impl apex, but fp16 '\n",
            "Dictionary: loading dictionary from /content/ParlAI/data/models/blender/blender_90M/model.dict\n",
            "[ num words =  54944 ]\n",
            "[TransformerGenerator: full interactive mode on.]\n",
            "Total parameters: 87,508,992 (87,508,992 trainable)\n",
            "[ Loading existing model params from /content/ParlAI/data/models/blender/blender_90M/model ]\n",
            "[ optional arguments: ] \n",
            "[  display_examples: False ]\n",
            "[  display_ignore_fields: label_candidates,text_candidates ]\n",
            "[  display_prettify: False ]\n",
            "[  interactive_task: True ]\n",
            "[ Main ParlAI Arguments: ] \n",
            "[  batchsize: 16 ]\n",
            "[  datapath: /content/ParlAI/data ]\n",
            "[  datatype: train ]\n",
            "[  download_path: /content/ParlAI/downloads ]\n",
            "[  dynamic_batching: None ]\n",
            "[  hide_labels: False ]\n",
            "[  image_mode: raw ]\n",
            "[  init_opt: None ]\n",
            "[  multitask_weights: [1.0, 3.0, 3.0, 3.0] ]\n",
            "[  numthreads: 1 ]\n",
            "[  show_advanced_args: False ]\n",
            "[  task: blended_skill_talk ]\n",
            "[ ParlAI Model Arguments: ] \n",
            "[  dict_class: parlai.core.dict:DictionaryAgent ]\n",
            "[  init_model: /checkpoint/parlai/zoo/new_reddit/newreddit_trained20190909_usedfordodeca/model ]\n",
            "[  model: transformer/generator ]\n",
            "[  model_file: /content/ParlAI/data/models/blender/blender_90M/model ]\n",
            "[ Safe Local Human Arguments: ] \n",
            "[  safety: all ]\n",
            "[ Local Human Arguments: ] \n",
            "[  local_human_candidates_file: None ]\n",
            "[  single_turn: False ]\n",
            "[ ParlAI Image Preprocessing Arguments: ] \n",
            "[  image_cropsize: 224 ]\n",
            "[  image_size: 256 ]\n",
            "[ Transformer Arguments: ] \n",
            "[  activation: gelu ]\n",
            "[  attention_dropout: 0.0 ]\n",
            "[  dropout: 0.1 ]\n",
            "[  embedding_size: 512 ]\n",
            "[  embeddings_scale: True ]\n",
            "[  ffn_size: 2048 ]\n",
            "[  learn_positional_embeddings: True ]\n",
            "[  model_parallel: False ]\n",
            "[  n_decoder_layers: -1 ]\n",
            "[  n_encoder_layers: -1 ]\n",
            "[  n_heads: 16 ]\n",
            "[  n_layers: 8 ]\n",
            "[  n_positions: 512 ]\n",
            "[  n_segments: 0 ]\n",
            "[  output_scaling: 1.0 ]\n",
            "[  relu_dropout: 0.0 ]\n",
            "[  share_word_embeddings: True ]\n",
            "[  variant: xlm ]\n",
            "[ Torch Generator Agent: ] \n",
            "[  beam_block_list_filename: None ]\n",
            "[  beam_block_ngram: 3 ]\n",
            "[  beam_context_block_ngram: 3 ]\n",
            "[  beam_delay: 30 ]\n",
            "[  beam_length_penalty: 0.65 ]\n",
            "[  beam_min_length: 20 ]\n",
            "[  beam_size: 10 ]\n",
            "[  compute_tokenized_bleu: False ]\n",
            "[  inference: beam ]\n",
            "[  skip_generation: False ]\n",
            "[  temperature: 1.0 ]\n",
            "[  topk: 10 ]\n",
            "[  topp: 0.9 ]\n",
            "[ TorchAgent Arguments: ] \n",
            "[  add_p1_after_newln: False ]\n",
            "[  delimiter: \n",
            " ]\n",
            "[  embedding_projection: random ]\n",
            "[  embedding_type: random ]\n",
            "[  force_fp16_tokens: True ]\n",
            "[  fp16: True ]\n",
            "[  fp16_impl: apex ]\n",
            "[  gpu: -1 ]\n",
            "[  history_add_global_end_token: None ]\n",
            "[  history_size: -1 ]\n",
            "[  interactive_mode: True ]\n",
            "[  label_truncate: 128 ]\n",
            "[  no_cuda: False ]\n",
            "[  person_tokens: False ]\n",
            "[  rank_candidates: False ]\n",
            "[  split_lines: False ]\n",
            "[  text_truncate: 512 ]\n",
            "[  truncate: -1 ]\n",
            "[  use_reply: label ]\n",
            "[ Optimizer Arguments: ] \n",
            "[  adafactor_eps: [1e-30, 0.001] ]\n",
            "[  adam_eps: 1e-08 ]\n",
            "[  betas: [0.9, 0.999] ]\n",
            "[  gradient_clip: 0.1 ]\n",
            "[  learningrate: 7.5e-06 ]\n",
            "[  momentum: 0 ]\n",
            "[  nesterov: True ]\n",
            "[  nus: [0.7] ]\n",
            "[  optimizer: adamax ]\n",
            "[  weight_decay: None ]\n",
            "[ Dictionary Arguments: ] \n",
            "[  bpe_debug: False ]\n",
            "[  dict_endtoken: __end__ ]\n",
            "[  dict_file: /content/ParlAI/data/models/blender/blender_90M/model.dict ]\n",
            "[  dict_initpath: None ]\n",
            "[  dict_language: english ]\n",
            "[  dict_lower: True ]\n",
            "[  dict_max_ngram_size: -1 ]\n",
            "[  dict_maxtokens: -1 ]\n",
            "[  dict_minfreq: 0 ]\n",
            "[  dict_nulltoken: __null__ ]\n",
            "[  dict_starttoken: __start__ ]\n",
            "[  dict_textfields: text,labels ]\n",
            "[  dict_tokenizer: bpe ]\n",
            "[  dict_unktoken: __unk__ ]\n",
            "[ BPEHelper Arguments: ] \n",
            "[  bpe_add_prefix_space: None ]\n",
            "[  bpe_merge: None ]\n",
            "[  bpe_vocab: None ]\n",
            "[ Learning Rate Scheduler: ] \n",
            "[  invsqrt_lr_decay_gamma: -1 ]\n",
            "[  lr_scheduler: reduceonplateau ]\n",
            "[  lr_scheduler_decay: 0.5 ]\n",
            "[  lr_scheduler_patience: 3 ]\n",
            "[  max_lr_steps: -1 ]\n",
            "[  update_freq: 1 ]\n",
            "[  warmup_rate: 0.0001 ]\n",
            "[  warmup_updates: -1 ]\n",
            "[ BST Interactive World: ] \n",
            "[  display_partner_persona: True ]\n",
            "[  include_initial_utterances: False ]\n",
            "[  include_personas: True ]\n",
            "[  safe_personas_only: True ]\n",
            "\u001b[1;31mEnter [DONE] if you want to end the episode, [EXIT] to quit.\u001b[0;0m\n",
            "[building data: /content/ParlAI/data/OffensiveLanguage]\n",
            "[ downloading: http://parl.ai/downloads/offensive_language/OffensiveLanguage.txt to /content/ParlAI/data/OffensiveLanguage/OffensiveLanguage.txt ]\n",
            "Downloading OffensiveLanguage.txt: 0.00B [00:00, ?B/s]\n",
            "[building data: /content/ParlAI/data/models/dialogue_safety/safety_models_v1.tgz]\n",
            "[ downloading: http://parl.ai/downloads/_models/dialogue_safety/safety_models_v1.tgz to /content/ParlAI/data/models/dialogue_safety/safety_models_v1.tgz ]\n",
            "Downloading safety_models_v1.tgz: 100% 2.23G/2.23G [01:23<00:00, 26.8MB/s]\n",
            "unpacking safety_models_v1.tgz\n",
            "[ warning: overriding opt['model'] to transformer/classifier (previously: transformer_classifier )]\n",
            "[ warning: overriding opt['model_file'] to /content/ParlAI/data/models/dialogue_safety/single_turn/model (previously: /checkpoint/edinan/20190828/safety_reddit/contiguous-dropout=0_multitask-weights=0.5,0.1,0.1,0.4,0.2_lr=5e-05_lr-scheduler-patience=3_lr-scheduler-decay=0.9_warmupupdates=1000/model )]\n",
            "[ warning: overriding opt['print_scores'] to True (previously: False )]\n",
            "[ Using CUDA ]\n",
            "Dictionary: loading dictionary from /content/ParlAI/data/models/dialogue_safety/single_turn/model.dict\n",
            "[ num words =  54944 ]\n",
            "Loading existing model parameters from /content/ParlAI/data/models/dialogue_safety/single_turn/model\n",
            "[creating task(s): blended_skill_talk]\n",
            "[ loading personas.. ]\n",
            "\n",
            "  [NOTE: In the BST paper both partners have a persona.\n",
            "         You can choose to ignore yours, the model never sees it.\n",
            "         In the Blender paper, this was not used for humans.\n",
            "         You can also turn personas off with --include-personas False]\n",
            "\n",
            "[building data: /content/ParlAI/data/blended_skill_talk]\n",
            "[ downloading: http://parl.ai/downloads/blended_skill_talk/blended_skill_talk.tar.gz to /content/ParlAI/data/blended_skill_talk/blended_skill_talk.tar.gz ]\n",
            "Downloading blended_skill_talk.tar.gz: 100% 38.1M/38.1M [00:02<00:00, 13.4MB/s]\n",
            "[ Checksum Successful ]\n",
            "unpacking blended_skill_talk.tar.gz\n",
            "[ downloading: http://parl.ai/downloads/blended_skill_talk/personas_list.txt to /content/ParlAI/data/blended_skill_talk/persona_list.txt ]\n",
            "Downloading persona_list.txt: 0.00B [00:01, ?B/s]\n",
            "[ Checksum Successful ]\n",
            "[ downloading: http://parl.ai/downloads/blended_skill_talk/topic_to_persona_list.txt to /content/ParlAI/data/blended_skill_talk/topic_to_persona_list.txt ]\n",
            "Downloading topic_to_persona_list.txt: 0.00B [00:00, ?B/s]\n",
            "[ Checksum Successful ]\n",
            "[ downloading: http://parl.ai/downloads/blended_skill_talk/ed_persona_topicifier__train__both_sides.json to /content/ParlAI/data/blended_skill_talk/ed_persona_topicifier__train__both_sides.json ]\n",
            "Downloading ed_persona_topicifier__train__both_sides.json: 0.00B [00:02, ?B/s]\n",
            "[ Checksum Successful ]\n",
            "[ downloading: http://parl.ai/downloads/blended_skill_talk/ed_persona_topicifier__train__experiencer_only.json to /content/ParlAI/data/blended_skill_talk/ed_persona_topicifier__train__experiencer_only.json ]\n",
            "Downloading ed_persona_topicifier__train__experiencer_only.json: 0.00B [00:01, ?B/s]\n",
            "[ Checksum Successful ]\n",
            "[ downloading: http://parl.ai/downloads/blended_skill_talk/ed_persona_topicifier__valid__experiencer_only.json to /content/ParlAI/data/blended_skill_talk/ed_persona_topicifier__valid__experiencer_only.json ]\n",
            "Downloading ed_persona_topicifier__valid__experiencer_only.json: 0.00B [00:03, ?B/s]\n",
            "[ Checksum Successful ]\n",
            "[ downloading: http://parl.ai/downloads/blended_skill_talk/ed_persona_topicifier__test__experiencer_only.json to /content/ParlAI/data/blended_skill_talk/ed_persona_topicifier__test__experiencer_only.json ]\n",
            "Downloading ed_persona_topicifier__test__experiencer_only.json: 0.00B [00:03, ?B/s]\n",
            "[ Checksum Successful ]\n",
            "[ downloading: http://parl.ai/downloads/blended_skill_talk/safe_personas_2.txt to /content/ParlAI/data/blended_skill_talk/safe_personas.txt ]\n",
            "Downloading safe_personas.txt: 0.00B [00:01, ?B/s]\n",
            "[ Checksum Successful ]\n",
            "Loading /content/ParlAI/data/blended_skill_talk/train.json.\n",
            "Saving to /content/ParlAI/data/blended_skill_talk/train.txt\n",
            "Loading /content/ParlAI/data/blended_skill_talk/valid.json.\n",
            "Saving to /content/ParlAI/data/blended_skill_talk/valid.txt\n",
            "Loading /content/ParlAI/data/blended_skill_talk/test.json.\n",
            "Saving to /content/ParlAI/data/blended_skill_talk/test.txt\n",
            "\u001b[0;34m[context]:\u001b[0;0m \u001b[1myour persona: i work part time in the campus library.\n",
            "your persona: i am living at home but hope to live in the dorms next year.\u001b[0;0m\n",
            "\u001b[0;34mEnter Your Message:\u001b[0;0m hello. i am sharan. what is your name?\n",
            "/pytorch/aten/src/ATen/native/BinaryOps.cpp:81: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1mnice to meet you sharan ! i am sam . what do you like to do for fun ?\u001b[0;0m\n",
            "\u001b[0;34mEnter Your Message:\u001b[0;0m i love to read books.\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1mthat ' s cool . i like to read too . what kind of books do you enjoy reading ?\u001b[0;0m\n",
            "\u001b[0;34mEnter Your Message:\u001b[0;0m i prefer science fiction although, i explore every genre\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1mi like science fiction as well . do you have any hobbies ? i enjoy playing sports .\u001b[0;0m\n",
            "\u001b[0;34mEnter Your Message:\u001b[0;0m i like gardening\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1mi ' ve never tried gardening , but i ' d love to try it . what types of plants do you grow ?\u001b[0;0m\n",
            "\u001b[0;34mEnter Your Message:\u001b[0;0m i like to supplement my own food. so i grow a lot of veggies.\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1mi love veggies ! i also like to grow fruits and vegetables . what are your favorite vegetables ?\u001b[0;0m\n",
            "\u001b[0;34mEnter Your Message:\u001b[0;0m i like every one. no favourites\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1mwhat are some of your favorite things to grow ? i like tomatoes , onions , and chili pepper .\u001b[0;0m\n",
            "\u001b[0;34mEnter Your Message:\u001b[0;0m [DONE]\n",
            "\n",
            "CHAT DONE.\n",
            "\n",
            "Your partner was playing the following persona:\n",
            "partner's persona: i am 7 foot tall.\n",
            "partner's persona: i'm hoping to play.\n",
            "\n",
            "[ Preparing new chat ... ]\n",
            "\n",
            "\u001b[0;34m[context]:\u001b[0;0m \u001b[1myour persona: i'm learning how to play the piano.\n",
            "your persona: i geocache in my spare time.\u001b[0;0m\n",
            "\u001b[0;34mEnter Your Message:\u001b[0;0m how tall are you?\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1mi ' m 6 feet tall . what about you ? what do you like to do for fun ?\u001b[0;0m\n",
            "\u001b[0;34mEnter Your Message:\u001b[0;0m i like to geocache\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1mgeocaching is a great hobby . do you have any hobbies ? i like going to restaurants .\u001b[0;0m\n",
            "\u001b[0;34mEnter Your Message:\u001b[0;0m im learning to play the piano\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1mthat ' s awesome ! i ' ve always wanted to learn to play . what kind of music do you play ?\u001b[0;0m\n",
            "\u001b[0;34mEnter Your Message:\u001b[0;0m i like lofi music\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1mi have never heard of lofi . i ' ll have to look it up . what ' s lofi ?\u001b[0;0m\n",
            "\u001b[0;34mEnter Your Message:\u001b[0;0m its about soft beats that help you think and relax\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1mthat sounds like a great way to relax . what else do you enjoy doing in your spare time ?\u001b[0;0m\n",
            "\u001b[0;34mEnter Your Message:\u001b[0;0m [DONE]\n",
            "\n",
            "CHAT DONE.\n",
            "\n",
            "Your partner was playing the following persona:\n",
            "partner's persona: i look forward to eating at restaurants.\n",
            "partner's persona: i work in a bank.\n",
            "\n",
            "[ Preparing new chat ... ]\n",
            "\n",
            "\u001b[0;34m[context]:\u001b[0;0m \u001b[1myour persona: i am a happy person.\n",
            "your persona: i love to take walks.\u001b[0;0m\n",
            "\u001b[0;34mEnter Your Message:\u001b[0;0m [EXIT]\n",
            "\n",
            "CHAT DONE.\n",
            "\n",
            "Your partner was playing the following persona:\n",
            "partner's persona: my grandsons favorite type of cake is chocolate.\n",
            "partner's persona: my children vist often.\n",
            "EPOCH DONE\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}